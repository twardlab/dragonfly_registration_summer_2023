{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dragonfly registration\n",
    "While other tasks used standard emlddmm, this setup has a different geometry which requires a more involved setup.\n",
    "\n",
    "Brain is cut into adjacent slabs.  Each slab deforms and shrinks/shifts/translates.  \n",
    "\n",
    "We will use a version of projection LDDMM for this.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In version 00, we just do one forward pass, and one reconstruction of the slices\n",
    "\n",
    "nothing nonlinear.  Everything looks nice so far and we have a reasonable initialization.\n",
    "\n",
    "note that I may need a smaller voxel size, so we can really see the end of the slices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in v01 I will start optimizing\n",
    "\n",
    "Next I will add nonlinaer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes.\n",
    "I think I will need to pad J so that there is some contrast at the ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In version 2 I add a fixed translation to each slice, just like a fixed trapezoid sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in version 4 I add deformation to each slab, less smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note this version for tme08"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Chris, you sent us a list of annotations like this on the previous dataset\n",
    "# do you have something like this for TME08 and other new datasets?\n",
    "# chris will check for other datasets and send to us (will take about a week).\n",
    "TME07-1_10x_01 = correct orientation\n",
    "TME07-1_10x_02 = flip horizontal; flip Z-order\n",
    "TME07-1_10x_03 = flip horizontal; flip Z-order\n",
    "TME07-1_10x_04 = flip horizontal; flip Z-order\n",
    "TME07-1_10x_05 = flip horizontal; flip Z-order\n",
    "TME07-1_10x_06 = flip horizontal; flip Z-order\n",
    "TME07-1_10x_07 = correct orientation\n",
    "TME07-1_10x_08 = correct orientation\n",
    "TME07-1_10x_09 = correct orientation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For TME07-1: [1,2,3,4,5]\n",
    "\n",
    "For TME08-1: [0,1,3,5,7]\n",
    "\n",
    "For TME09-1: [0,1]\n",
    "\n",
    "For TME10-1: [0,1,2,5,7,8]\n",
    "\n",
    "For TME10-3: [1,3,7]\n",
    "\n",
    "For TME12-1: [0,1,2,3,5,6,7]\n",
    "\n",
    "For TME20-1: [0,1,4,8]\n",
    "\n",
    "For Q140_MORF/MQC06-2: [0,1,2,3,4,5,6,7]\n",
    "\n",
    "For Q140_MORF/MQC09-3: [0,1,2,3,4,5,6,7]\n",
    "\n",
    "For Q140_MORF/MQC18-3: [0,1,2,3,4,5,6,7]\n",
    "\n",
    "For Q140_MORF/MQC82-2: [0,1,2,3,4,5,6,7]\n",
    "\n",
    "For KO-Het_MORF/HpcaKO-Camk-MORF3-D1tom_Hpca5-2: [0,2]\n",
    "\n",
    "For KO-Het_MORF/Trank1KO-Camk-MORF3-D1tom_Trank1-2-3: []\n",
    "\n",
    "For KO-Het_MORF/Sp9Het-Camk-MORF3-D1tom_Sp9-3-2: [0]\n",
    "\n",
    "For KO-Het_MORF/Zswim6Het-Camk-MORF3-D1tom_Zswim4-1: []\n",
    "\n",
    "For Q140_MORF_D1/Camk-MORF3-D1Tom_12m_hTME15-1: [0,1]\n",
    "\n",
    "For Q140_MORF_D1/Camk-MORF3-D1Tom-Q140_12m_hTME15-2: [5]\n",
    "\n",
    "For Q140_MORF_D1/Camk-MORF3-D1Tom-Q140_12m_hTME18-1: []\n",
    "\n",
    "For Q140_MORF_D1/Camk-MORF3-D1Tom_12m_hTME19-2: []\n",
    "\n",
    "For Q140_MORF/Shasha_Q140/Camk-MORF3_12m_MQC06-2: [0,1,2,3,4,5]\n",
    "\n",
    "For Q140_MORF/Shasha_Q140/Camk-MORF3_12m_MQC15-1: [0,1,2,3,4]\n",
    "\n",
    "For Q140_MORF/Shasha_Q140/Camk-MORF3_12m_MQC18-3: [0,1,2,3,4,5,6]\n",
    "\n",
    "For Q140_MORF/Shasha_Q140/Camk-MORF3-Q140_12m_MQC07-5: []\n",
    "\n",
    "For Q140_MORF/Shasha_Q140/Camk-MORF3-Q140_12m_MQC09-3: [0,1,3,4,5,6]\n",
    "\n",
    "For Q140_MORF/Shasha_Q140/Camk-MORF3-Q140_12m_MQC6-4 (prev 6-3)_downsampled: [0,1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "PIL.__file__\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib notebook\n",
    "%matplotlib widget\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from glob import glob\n",
    "\n",
    "import os\n",
    "from os.path import join,split,splitext\n",
    "from os import makedirs\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# sys.path.append('/ifshome/abenneck')\n",
    "sys.path.append('/home/abenneck')\n",
    "import importlib as imp\n",
    "import donglab_workflows as dw\n",
    "imp.reload(dw)\n",
    "\n",
    "# for now add emlddmm library for registration\n",
    "from emlddmm import emlddmm\n",
    "imp.reload(emlddmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Atlas + Load Atlas Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists of all potential inputs for 'brain':\n",
    "- [TME08-1, TME10-1, TME10-3, TME12-1, TME20-1]\n",
    "- [Hpca5-2, Sp9-3-2, Trank1-2-3, Zswim4-1]\n",
    "- [MQC06-2, MQC09-3, MQC18-3, MQC82-2]\n",
    "- [hTME15-1, hTME15-2, hTME18-1, hTME19-2]\n",
    "- [12m_MQC06-2, 12m_MQC15-1, 12m_MQC18-3, 12m_MQC07-5, 12m_MQC09-3, 12m_MQC6-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of all potential inputs for 'orientation':\n",
    "- 'L' for KO-Het_MORF brains\n",
    "- 'R' for Q140_MORF brains\n",
    "- 'W' for whole brains (TME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain = 'TME07-1'\n",
    "# brain = 'TME08-1'\n",
    "# brain = 'TME09-1'\n",
    "# brain = 'TME10-1'\n",
    "# brain = 'TME10-3'\n",
    "# brain = 'TME12-1'\n",
    "# brain = 'TME20-1'\n",
    "# brain = 'Hpca5-2'\n",
    "# brain = 'Sp9-3-2'\n",
    "# brain = 'Trank1-2-3'\n",
    "# brain = 'Zswim4-1'\n",
    "# brain = 'MQC06-2'\n",
    "# brain = 'MQC09-3'\n",
    "# brain = 'MQC18-3'\n",
    "# brain = 'MQC82-2'\n",
    "# brain = 'hTME15-1'\n",
    "# brain = 'hTME15-2'\n",
    "# brain = 'hTME18-1'\n",
    "# brain = 'hTME19-2'\n",
    "# brain = '12m_MQC06-2'\n",
    "brain = '12m_MQC15-1'\n",
    "# brain = '12m_MQC18-3'\n",
    "# brain = '12m_MQC07-5'\n",
    "# brain = '12m_MQC09-3'\n",
    "# brain = '12m_MQC6-4'\n",
    "\n",
    "# Change to 'L' or 'R' depending on orientation of hemisphere-only images and 'W' if whole brain\n",
    "orientation = 'W'\n",
    "\n",
    "if brain in ['TME08-1', 'TME10-1', 'TME10-3', 'TME12-1', 'TME20-1', 'TME07-1', 'TME09-1']:\n",
    "    brain_path = brain\n",
    "elif brain in ['MQC06-2', 'MQC09-3', 'MQC18-3', 'MQC82-2']: # The original HD brains\n",
    "    brain_path = f'Q140_MORF/{brain}'\n",
    "    orientation = 'R' \n",
    "elif '12m' in brain: # The new HD brains\n",
    "    orientation = 'L'\n",
    "    if '06-2' in brain or '15-1' in brain or '18-3' in brain:\n",
    "        brain_path = f'Q140_MORF/Shasha_Q140/Camk-MORF3_{brain}'\n",
    "    elif '09-3' in brain:\n",
    "        brain_path = f'Q140_MORF/Shasha_Q140/Camk-MORF3-Q140_{brain}'\n",
    "    elif '07-5' in brain:\n",
    "        brain_path = f'Q140_MORF/Shasha_Q140/Camk-MORF3-Q140_{brain}'\n",
    "        orientation = 'R'\n",
    "    elif '6-4' in brain:\n",
    "        brain_path = f'Q140_MORF/Shasha_Q140/Camk-MORF3-Q140_12m_MQC6-4 (prev 6-3)'\n",
    "        orientation = 'L'\n",
    "    else:\n",
    "        raise Exception('Invalid brain')\n",
    "elif 'hTME' in brain:\n",
    "    orientation = 'R'\n",
    "    if 'hTME15-1' in brain or 'hTME19-2' in brain:\n",
    "        brain_path = f'Q140_MORF_D1/Camk-MORF3-D1Tom_12m_{brain}'\n",
    "    elif 'hTME15-2' in brain or 'hTME18-1' in brain:\n",
    "        brain_path = f'Q140_MORF_D1/Camk-MORF3-D1Tom-Q140_12m_{brain}'\n",
    "    else:\n",
    "        raise Exception('Invalid brain')\n",
    "else: # KO-Het_MORF\n",
    "    orientation = 'L' \n",
    "    if 'Hpca' in brain:\n",
    "        brain_path = f'KO-Het_MORF/HpcaKO-Camk-MORF3-D1tom_Hpca5-2'\n",
    "    elif 'Sp9' in brain:\n",
    "        brain_path = f'KO-Het_MORF/Sp9Het-Camk-MORF3-D1tom_Sp9-3-2'\n",
    "    elif 'Trank' in brain:\n",
    "        brain_path = f'KO-Het_MORF/Trank1KO-Camk-MORF3-D1tom_Trank1-2-3'\n",
    "    elif 'Zswim' in brain:\n",
    "        brain_path = f'KO-Het_MORF/Zswim6Het-Camk-MORF3-D1tom_Zswim4-1'\n",
    "    else:\n",
    "        raise Exception('Invalid brain')\n",
    "\n",
    "output_prefix = f'/home/abenneck/dragonfly_work/{brain}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load atlas images\n",
    "atlas_names = [\n",
    "    '/nafs/dtward/allen_vtk/allen_vtk/ara_nissl_50.vtk',\n",
    "    '/nafs/dtward/allen_vtk/allen_vtk/average_template_50.vtk',\n",
    "]\n",
    "\n",
    "seg_name = '/nafs/dtward/allen_vtk/allen_vtk/annotation_50.vtk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = []\n",
    "for atlas_name in atlas_names:\n",
    "    xI,I_,title,names = emlddmm.read_data(atlas_name)\n",
    "    I_ = I_.astype(np.float32)\n",
    "    I_ /= np.mean(np.abs(I_))\n",
    "\n",
    "    # Will zero-out atlas image for the hemisphere we are NOT aligning\n",
    "    if orientation == 'R': # For images only containing a LEFT hemisphere\n",
    "        I_[:,:,:int(np.shape(I_)[2]/2),:] = np.zeros([np.shape(I_)[0],np.shape(I_)[1],int(np.shape(I_)[2]/2),np.shape(I_)[3]])\n",
    "    elif orientation == 'L': # For images only containing a RIGHT hemisphere (+1 brings back fig[1,2])\n",
    "        I_[:,:,int(np.shape(I_)[2]/2 + 1):,:] = np.zeros([np.shape(I_)[0],np.shape(I_)[1],int(np.shape(I_)[2]/2 - 1),np.shape(I_)[3]])\n",
    "    else:\n",
    "        print(f'{brain} contains whole-brain images, not hemispheres')\n",
    "        \n",
    "    I.append(I_)\n",
    "    \n",
    "I = np.concatenate(I)   \n",
    "I[0] = I[0]**0.25\n",
    "I[0] /= np.mean(np.abs(I_[0]))\n",
    "dI = np.array([x[1] - x[0] for x in xI])\n",
    "XI = np.stack(np.meshgrid(*xI,indexing='ij'),-1)\n",
    "\n",
    "# {Plot figure\n",
    "fig,ax = emlddmm.draw(I,xI,vmin=0)\n",
    "fig.canvas.draw()\n",
    "\n",
    "# Shows 2 images as a series of coronal, sagittal, and axial (top => down)\n",
    "# - Magenta is 1st image and green is a serial 2-photon image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using emlddmm.orientation_to_orientation('ARI','IRA')\n",
    "- First argument will be constant ('ARI'), represents orientations of Atlas\n",
    "- I will need to change second argument until I find proper alignment\n",
    "\n",
    "Create an acronym of some order: containing 3 letters\n",
    "- Ex: 'ALS'\n",
    "\n",
    "First row: A <=> P\n",
    "Second row: R <=> L\n",
    "Third row: I <=> S\n",
    "\n",
    "Order of acronym depends on order of rows \n",
    "\n",
    "For new brains, the third row is either A or P\n",
    "- The first and second rows could be either R/L or I/S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Directory for Data to be Registered (TMEXX-Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'TME07-1' in brain:\n",
    "    target_dir = '/nafs/dtward/dong/dragonfly_03_2022'\n",
    "else:\n",
    "    target_dir = f'/panfs/dong/3D_registration/Yang_MORF_DragonFly/{brain_path}_downsampled/10x/ch_0_pipeline_building'\n",
    "\n",
    "if brain in ['MQC06-2', 'MQC09-3', 'MQC82-3', '12m_MQC15-1', '12m_MQC09-3'] or 'hTME' in brain:\n",
    "    target_pattern = '*10X*ch_0_*.npz'\n",
    "elif 'TME07-1' in brain:\n",
    "    target_pattern = '*10x*_channel_0*.npz'\n",
    "elif brain in ['12m_MQC06-2', '12m_MQC18-3']:\n",
    "    target_pattern = '*10x*ch_0_*.npz'\n",
    "    target_pattern_1 = '*10X*ch_0_*.npz'\n",
    "else:\n",
    "    target_pattern = '*10x*ch_0_*.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_files = glob(join(target_dir,target_pattern))\n",
    "# target_files.sort()\n",
    "# target_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_files = []\n",
    "for rootdir,directories,files in os.walk(target_dir):\n",
    "    matched = glob(join(rootdir,target_pattern))\n",
    "    if matched:\n",
    "        target_files.extend(matched)\n",
    "    # Some .npz files include '10x' and some include '10X'\n",
    "    if brain in ['12m_MQC06-2', '12m_MQC18-3']:\n",
    "        matched = glob(join(rootdir,target_pattern_1))\n",
    "        if matched:\n",
    "            target_files.extend(matched)\n",
    "target_files.sort()\n",
    "print(target_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When sorted alphabetically, the file names of some brains were not in proper slab order, so I put the files in order manually here \n",
    "temp_target_files = []\n",
    "if brain == '12m_MQC15-1':\n",
    "    temp_target_files.append(target_files[2])\n",
    "    temp_target_files.append(target_files[3])\n",
    "    temp_target_files.append(target_files[4])\n",
    "    temp_target_files.append(target_files[0])\n",
    "    temp_target_files.append(target_files[1])\n",
    "    target_files = temp_target_files\n",
    "elif brain == '12m_MQC18-3':\n",
    "    temp_target_files.append(target_files[0])\n",
    "    temp_target_files.append(target_files[5])\n",
    "    temp_target_files.append(target_files[6])\n",
    "    temp_target_files.append(target_files[1])\n",
    "    temp_target_files.append(target_files[2])\n",
    "    temp_target_files.append(target_files[3])\n",
    "    temp_target_files.append(target_files[4])\n",
    "    target_files = temp_target_files    \n",
    "elif brain == '12m_MQC09-3':\n",
    "    temp_target_files.append(target_files[3])\n",
    "    temp_target_files.append(target_files[4])\n",
    "    temp_target_files.append(target_files[0])\n",
    "    temp_target_files.append(target_files[5])\n",
    "    temp_target_files.append(target_files[6])\n",
    "    temp_target_files.append(target_files[1])\n",
    "    temp_target_files.append(target_files[2])\n",
    "    target_files = temp_target_files \n",
    "elif brain == '12m_MQC6-4':\n",
    "    temp_target_files.append(target_files[1])\n",
    "    temp_target_files.append(target_files[2])\n",
    "    temp_target_files.append(target_files[4])\n",
    "    temp_target_files.append(target_files[3])\n",
    "    temp_target_files.append(target_files[5])\n",
    "    temp_target_files.append(target_files[0])\n",
    "    target_files = temp_target_files\n",
    "target_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a Maximum Intensity Projection of either slice 'idx' or slice '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###### test\n",
    "idx = 2\n",
    "data = np.load(target_files[idx],allow_pickle=True)\n",
    "# data = np.load(target_files[-1],allow_pickle=True)\n",
    "print([k for k in data])\n",
    "\n",
    "if 'TME07-1' in brain:\n",
    "    W_ = data['W']\n",
    "else:\n",
    "    W_ = data['w']\n",
    "\n",
    "I_ = data['I']\n",
    "vmin = np.quantile(I_[W_>0.99],0.1)\n",
    "vmax = np.quantile(I_[W_>0.99],0.9)\n",
    "I_.shape\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(np.max(I_,0),vmin=vmin)\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(np.max(W_,0))\n",
    "ax.set_title(os.path.split(target_files[idx])[-1])\n",
    "\n",
    "# 1st panel is a maximum intensity projection (Common way to view microscopy today, especially w fluorescence labeling)\n",
    "# No info acquired in purple corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "Js = []\n",
    "xJs = []\n",
    "Ws = []\n",
    "dJs = []\n",
    "DJs = []\n",
    "for fname in target_files:\n",
    "    print(fname)\n",
    "    data = np.load(fname,allow_pickle=True)\n",
    "    Js.append(data['I'][None])    \n",
    "    \n",
    "    # We decided to ignore voxel positions and use zero-mean convention b/c it is more numerically stable\n",
    "    # data['xI'] is a list of 3 1d arrays with z,y,x locations \n",
    "    # xJs.append(data['xI'])\n",
    "    if 'TME' in brain:\n",
    "        xJs.append([d-np.mean(d) for d in data['xI']])\n",
    "    else:\n",
    "        xJs.append([data['xI'][0] - np.mean(data['xI'][0]), data['xI'][1] - np.mean(data['xI'][1]), data['xI'][2]])\n",
    "        \n",
    "\n",
    "    if 'W' in data or 'w' in data:\n",
    "        if 'W' in data:\n",
    "            key = 'W'\n",
    "        else:\n",
    "            key = 'w'\n",
    "        W_ = data[key]\n",
    "        if W_.ndim == 4:\n",
    "            W_ = W_[0]\n",
    "        Ws.append(W_)\n",
    "    else:\n",
    "        #Ws.append(np.zeros_like(Js[0]))\n",
    "        # I think this should be ones\n",
    "        Ws.append(np.ones_like(Js[0]))\n",
    "    \n",
    "    \n",
    "    # we need to normalize to [0,1]\n",
    "    mymin = np.quantile(Js[-1][Ws[-1][None]>0.99],0.05)\n",
    "    mymax = np.quantile(Js[-1][Ws[-1][None]>0.99],0.99)\n",
    "    #print(mymin,mymax)\n",
    "    Js[-1] = (Js[-1] - mymin)/(mymax - mymin)\n",
    "    \n",
    "    # I'd like to squash the bright signal\n",
    "    signJ = np.sign(Js[-1])\n",
    "    Js[-1] = signJ*abs(Js[-1])**0.25\n",
    "\n",
    "    \n",
    "    # we need to normalize to [0,1] again!\n",
    "    mymin = np.quantile(Js[-1][Ws[-1][None]>0.99],0.05)\n",
    "    mymax = np.quantile(Js[-1][Ws[-1][None]>0.99],0.99)\n",
    "    #print(mymin,mymax)\n",
    "    Js[-1] = (Js[-1] - mymin)/(mymax - mymin)\n",
    "    # after scaling I'm going to zero out the low signals (new feb 2 2023)\n",
    "    Js[-1][Js[-1]<0.0] = 0.0\n",
    "    # also I think the weights are not strong enough\n",
    "    Ws[-1][Ws[-1]<0.999] = 0.0\n",
    "    \n",
    "    dJs.append([x[1]-x[0] for x in xJs[-1]])\n",
    "    DJs.append(np.prod(dJs[-1]) )\n",
    "\n",
    "# Js[i].shape[1] == xJs[i][0].shape[0]\n",
    "\n",
    "    # note, sometimes xJs don't match Js\n",
    "    for s in [-1,-2,-3]:\n",
    "        if len(xJs[-1][s]) != Js[-1].shape[s]:\n",
    "            print('mismatch')\n",
    "            print(f'x size {len(xJs[-1][s])} doesn\\'t match J size {Js[-1].shape[s]}')\n",
    "            n = Js[-1].shape[s] - len(xJs[-1][s]) \n",
    "            d = xJs[-1][s][1] - xJs[-1][s][0]\n",
    "            xJs[-1][s] = np.concatenate((xJs[-1][s],[xJs[-1][s][-1]+d ]))\n",
    "    \n",
    "    # # note, sometimes xJs don't match Js\n",
    "    # s = -1\n",
    "    # if len(xJs[-1][s]) != Js[-1].shape[s]:\n",
    "    #     print('mismatch')\n",
    "    #     print(f'x size {len(xJs[-1][s])} doesn\\'t match J size {Js[-1].shape[s]}')\n",
    "    #     n = Js[-1].shape[s] - len(xJs[-1][s]) \n",
    "    #     d = xJs[-1][s][1] - xJs[-1][s][0]\n",
    "    #     xJs[-1][s] = np.concatenate((xJs[-1][s],[xJs[-1][s][-1]+d ]))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots()\n",
    "ax.hist(Js[-1][Ws[-1][None]>0.99].ravel(),100)\n",
    "\n",
    "# Histogram of intensity values of the last slice [-1], using logical indexing to only consider portion of image where \n",
    "# data was acquired (yellow in 2nd panel of above image (Ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints out size and shape\n",
    "# (***) Check that Js, Ws, and Xs are all the same size\n",
    "# --- Xs tells us the location of every pixel\n",
    "# (***) Check which of 2 possible ways that Xs are defined\n",
    "# - (1) Origin placed in center of image (Mean of Xs is ~0)\n",
    "# - (2) Origin placed wherever the microscope declared it to be\n",
    "for i in range(len(Js)):\n",
    "    print(f'idx {i}:')\n",
    "    if Js[i].shape[0] != 1:\n",
    "        print(\"Incorrect dimension Js[i].shape[0]\")\n",
    "        \n",
    "    if Js[i].shape[1] == Ws[i].shape[0] and Js[i].shape[1] == xJs[i][0].shape[0]:\n",
    "        print(f\"Correct dimension 1: {Js[i].shape[1]}\")\n",
    "    else:\n",
    "        print(f'(***) Incorrect dimension 1: {Js[i].shape[1]} ?= {Ws[i].shape[0]} and {Js[i].shape[1]} ?= {xJs[i][0].shape[0]}')\n",
    "        \n",
    "    if Js[i].shape[2] == Ws[i].shape[1] and Js[i].shape[2] == xJs[i][1].shape[0]:\n",
    "        print(f\"Correct dimension 2: {Js[i].shape[2]}\")    \n",
    "    else:\n",
    "        print(f'(***) Incorrect dimension 2: {Js[i].shape[2]} ?= {Ws[i].shape[1]} and {Js[i].shape[2]} ?= {xJs[i][1].shape[0]}')\n",
    "        \n",
    "    if Js[i].shape[3] == Ws[i].shape[2] and Js[i].shape[3] == xJs[i][2].shape[0]:\n",
    "        print(f\"Correct dimension 3: {Js[i].shape[3]}\")\n",
    "    else:\n",
    "        print(f'(***) Incorrect dimension 1: {Js[i].shape[3]} ?= {Ws[i].shape[2]} and {Js[i].shape[3]} ?= {xJs[i][2].shape[0]}')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation (Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to pad everything, so that we could see the edges of the slab (for alignment purposes)\n",
    "for i in range(len(Js)):\n",
    "    Ji = Js[i]\n",
    "    Wi = Ws[i]\n",
    "    xJi = xJs[i]\n",
    "    dJi = dJs[i]\n",
    "    \n",
    "    # find the 1% quantile\n",
    "    #val = np.quantile(Ji[Wi[None]>=0.99],0.05)\n",
    "    val = np.quantile(Ji[Wi[None]>=0.99],0.1)\n",
    "    #val = 0.0\n",
    "    npad = 2\n",
    "    Ji = np.pad(Ji,((0,0),(npad,npad),(0,0),(0,0)), constant_values=val)\n",
    "    Wi = np.pad(Wi,((npad,npad),(0,0),(0,0)), constant_values=1.0)\n",
    "    for j in range(npad):\n",
    "        # Grows the Xs, so that we know the location of the padded pixesl too\n",
    "        xJi[0] = np.concatenate((xJi[0][0][None]-dJi[0], xJi[0], xJi[0][-1][None]+dJi[0]))\n",
    "    \n",
    "    Js[i] = Ji\n",
    "    Ws[i] = Wi\n",
    "    xJs[i] = xJi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks that Js, Ws, and Xs are still same size\n",
    "for i in range(len(Js)):\n",
    "    print(f'idx {i}:')\n",
    "    if Js[i].shape[0] != 1:\n",
    "        print(\"Incorrect dimension Js[i].shape[0]\")\n",
    "        \n",
    "    if Js[i].shape[1] == Ws[i].shape[0] and Js[i].shape[1] == xJs[i][0].shape[0]:\n",
    "        print(f\"Correct dimension 1: {Js[i].shape[1]}\")\n",
    "    else:\n",
    "        print(f'(***) Incorrect dimension 1: {Js[i].shape[1]} ?= {Ws[i].shape[0]} and {Js[i].shape[1]} ?= {xJs[i][0].shape[0]}')\n",
    "        \n",
    "    if Js[i].shape[2] == Ws[i].shape[1] and Js[i].shape[2] == xJs[i][1].shape[0]:\n",
    "        print(f\"Correct dimension 2: {Js[i].shape[2]}\")    \n",
    "    else:\n",
    "        print(f'(***) Incorrect dimension 2: {Js[i].shape[2]} ?= {Ws[i].shape[1]} and {Js[i].shape[2]} ?= {xJs[i][1].shape[0]}')\n",
    "        \n",
    "    if Js[i].shape[3] == Ws[i].shape[2] and Js[i].shape[3] == xJs[i][2].shape[0]:\n",
    "        print(f\"Correct dimension 3: {Js[i].shape[3]}\")\n",
    "    else:\n",
    "        print(f'(***) Incorrect dimension 1: {Js[i].shape[3]} ?= {Ws[i].shape[2]} and {Js[i].shape[3]} ?= {xJs[i][2].shape[0]}')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception('Check Sizes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (****) Figures 4 & 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(I):\n",
    "    I = np.copy(I)\n",
    "    I[I<0] = 0\n",
    "    I[I>1] = 1\n",
    "    return I\n",
    "def draw_stack(Js,xJs,fig=None,**kwargs):\n",
    "    '''\n",
    "    stack is on the first axis\n",
    "    note there is an issue with sharex and removing the axis labels\n",
    "    also an issue cause the images are different number of slices\n",
    "    Not using now\n",
    "    TODO: make sure this will work with numpy or torch\n",
    "    avoid copying too much\n",
    "\n",
    "    '''\n",
    "    #print(kwargs)\n",
    "    if 'vmin' in kwargs:\n",
    "        vmin = kwargs.pop('vmin')\n",
    "    else:\n",
    "        vmin = np.min([np.min(np.array(J)) for J in Js])\n",
    "    if 'vmax' in kwargs:\n",
    "        vmax = kwargs.pop('vmax')\n",
    "    else:\n",
    "        vmax = np.min([np.max(np.array(J)) for J in Js])    \n",
    "    print(kwargs)\n",
    "    \n",
    "    \n",
    "    n = len(Js)\n",
    "    if fig is None:\n",
    "        figsize = (5,10)\n",
    "        figsize = None\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "    else:\n",
    "        fig.clf()\n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            ax0 = fig.add_subplot(n,3,3*i+1)\n",
    "            ax = ax0\n",
    "        else:\n",
    "            ax0 = None\n",
    "            ax = fig.add_subplot(n,3,3*i+1,sharex=ax0,sharey=ax0)\n",
    "        # note I make a copy here\n",
    "        toshow = np.array(Js[i][:,Js[i].shape[1]//2]).transpose(1,2,0)\n",
    "        if toshow.shape[-1] == 1:\n",
    "            toshow = np.concatenate((toshow,toshow,toshow),-1)\n",
    "        elif toshow.shape[-1] == 2:\n",
    "            toshow = np.stack((toshow[...,0],toshow[...,1],toshow[...,0]),-1)\n",
    "        else:\n",
    "            toshow = toshow[...,:3]\n",
    "        toshow -= vmin\n",
    "        toshow /= vmax-vmin\n",
    "        xJ = xJs[i]\n",
    "        dJ = [x[1]-x[0] for x in xJ]\n",
    "        extent = (xJ[-1][0]-dJ[-1]*0.5,xJ[-1][-1]+dJ[-1]*0.5,\n",
    "                 xJ[-2][-1]+dJ[-2]*0.5,xJ[-2][0]-dJ[-2]*0.5)\n",
    "        ax.imshow(clip(toshow),extent=extent,**kwargs)\n",
    "        #if i < n-1:\n",
    "        #    ax.set_xticks([])\n",
    "                \n",
    "        if i == 0:\n",
    "            ax1 = fig.add_subplot(n,3,3*i+2)\n",
    "            ax = ax1\n",
    "        else:\n",
    "            ax1 = None\n",
    "            ax = fig.add_subplot(n,3,3*i+2,sharex=ax1,sharey=ax1)\n",
    "        toshow = np.array(Js[i][:,:,Js[i].shape[2]//2]).transpose(1,2,0)\n",
    "        if toshow.shape[-1] == 1:\n",
    "            toshow = np.concatenate((toshow,toshow,toshow),-1)\n",
    "        elif toshow.shape[-1] == 2:\n",
    "            toshow = np.stack((toshow[...,0],toshow[...,1],toshow[...,0]),-1)\n",
    "        else:\n",
    "            toshow = toshow[...,:3]\n",
    "        toshow -= vmin\n",
    "        toshow /= vmax-vmin\n",
    "        \n",
    "        \n",
    "        extent = (xJ[-1][0]-dJ[-1]*0.5,xJ[-1][-1]+dJ[-1]*0.5,\n",
    "                 xJ[-3][-1]+dJ[-3]*0.5,xJ[-3][0]-dJ[-3]*0.5)        \n",
    "        ax.imshow(clip(toshow),extent=extent,**kwargs)\n",
    "        ax.set_aspect('auto')\n",
    "        #if i < n-1:\n",
    "        #    ax.set_xticks([])\n",
    "        \n",
    "        \n",
    "        if i == 0:\n",
    "            ax2 = fig.add_subplot(n,3,3*i+3)\n",
    "            ax = ax2\n",
    "        else:\n",
    "            ax2 = None\n",
    "            ax = fig.add_subplot(n,3,3*i+3,sharex=ax2,sharey=ax2)\n",
    "        toshow = np.array(Js[i][:,:,:,Js[i].shape[3]//2]).transpose(1,2,0)\n",
    "        if toshow.shape[-1] == 1:\n",
    "            toshow = np.concatenate((toshow,toshow,toshow),-1)\n",
    "        elif toshow.shape[-1] == 2:\n",
    "            toshow = np.stack((toshow[...,0],toshow[...,1],toshow[...,0]),-1)            \n",
    "        else:\n",
    "            toshow = toshow[...,:3]\n",
    "        toshow -= vmin\n",
    "        toshow /= vmax-vmin\n",
    "        extent = (xJ[-2][0]-dJ[-2]*0.5,xJ[-2][-1]+dJ[-2]*0.5,\n",
    "                 xJ[-3][-1]+dJ[-3]*0.5,xJ[-3][0]-dJ[-3]*0.5)\n",
    "        ax.imshow(clip(toshow),extent=extent,**kwargs)\n",
    "        ax.set_aspect('auto')\n",
    "        #if i < n-1:\n",
    "        #    ax.set_xticks([])\n",
    "        plt.subplots_adjust(wspace=0,hspace=0)\n",
    "        \n",
    "    return fig,None # later I will return ax\n",
    "        \n",
    "\n",
    "vminJ = 0.99\n",
    "vmaxJ = 1.01\n",
    "\n",
    "vminJ = 0.0\n",
    "vmaxJ = 1.0\n",
    "\n",
    "fig,ax = draw_stack(Js,xJs,vmin=vminJ,vmax=vmaxJ)\n",
    "fig.canvas.draw()\n",
    "fig,ax = draw_stack([w[None] for w in Ws],xJs,vmin=0,vmax=1)\n",
    "fig.canvas.draw()\n",
    "    \n",
    "# Looking at the axis label, we see that the origin is the center of the images\n",
    "# -- Slices for each slab\n",
    "\n",
    "# 2nd panel - Anywhere with black is missing info (Similar to the yellow/purple from before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to firm up the model\n",
    "# as usual, I will start with just linear\n",
    "# then I'll add the projection step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets convert to torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Change the shape of the atlas in 3D to match our dataset\n",
    "2. Then we match the pose via linear transformations\n",
    "3. Cut out 50 um slabs from the atlas\n",
    "4. Allow a per-slab change in shape (1m parameters to estimate)\n",
    "5. Allow a per-slab change in pose (Orientation and scale, ~O(10) parameters to estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = np.copy(I)\n",
    "xInp = [np.copy(x) for x in xI]\n",
    "Jnp = [np.copy(Ji) for Ji in Js]\n",
    "xJnp = [[np.copy(x) for x in xJ] for xJ in xJs]\n",
    "Wnp = [np.copy(Wi) for Wi in Ws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "device = 'cuda:1'\n",
    "dtype = torch.float64\n",
    "I = torch.tensor(Inp,device=device,dtype=dtype)\n",
    "xI = [torch.tensor(x,device=device,dtype=dtype) for x in xInp]\n",
    "J = [torch.tensor(Ji,device=device,dtype=dtype) for Ji in Jnp]\n",
    "W = [torch.tensor(Wi,device=device,dtype=dtype) for Wi in Wnp]\n",
    "xJ = [[torch.tensor(x,device=device,dtype=dtype) for x in xJi] for xJi in xJnp]\n",
    "XJ = [ torch.stack(torch.meshgrid(x[0],x[1],x[2],indexing='ij'),-1) for x in xJ]\n",
    "# note I'm stacking at the end\n",
    "# I think I may have to stack at the start\n",
    "XI = torch.stack(torch.meshgrid(*xI,indexing='ij'),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets build a trapezoid function\n",
    "dslice = 500.0 # 500 micron slices\n",
    "def trapezoid(x,i):\n",
    "    # if it is in the middle\n",
    "    d = torch.abs(x - (i - (len(J)-1)/2.0)*dslice)\n",
    "    out = (d < dslice/2.0)*1.0 + (d >= dslice/2.0)*(d < dslice/2.0+dI[0])*(1.0 - (d-dslice/2.0)/dI[0])    \n",
    "    return out\n",
    "def trapezoid(x,i):\n",
    "    # if it is in the middle\n",
    "    d = torch.abs(x - (i - (len(J)-1)/2.0)*dslice)\n",
    "    out = (d < dslice/2.0 - dI[0])*1.0 + (d >= dslice/2.0 - dI[0])*(d < dslice/2.0+dI[0])*(1.0 - (d-dslice/2.0)/dI[0])*0.5\n",
    "    return out\n",
    "# I want the edge to be at 0.5, and take one voxel to go up or down\n",
    "t = torch.linspace(-3000,3000,1000)\n",
    "f,ax = plt.subplots()\n",
    "ax.plot(t,trapezoid(t,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DI = torch.prod(torch.tensor(dI,device=device,dtype=dtype))\n",
    "\n",
    "W_ = (I[0] > 0).to(dtype)\n",
    "DW = torch.stack(torch.gradient(W_,spacing=dI.tolist(),dim=(0,1,2)),-1)\n",
    "emlddmm.draw(DW.permute(-1,0,1,2))\n",
    "\n",
    "# Attempt to estimate an inner product on the space parameters over which we are optimizing\n",
    "# -- Must be estimated - 12x12 matrix which tells us how to compute\n",
    "# -- Modified dot product which allows us to perform gradient descent in a better way\n",
    "# -- Norm will be big if it changes the image a lot and small if it changes a little\n",
    "# Color corresponds to the direction of the derivative (X-, Y-, and Z-)\n",
    "# -- Measures how changing the affine matrix changes the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the 12x12 matrix using the derivative of the image\n",
    "gid = torch.zeros(12,12,device=device,dtype=dtype)\n",
    "\n",
    "count0 = 0\n",
    "for i0 in range(3):\n",
    "    for j0 in range(4):\n",
    "        E0 = ((torch.arange(4,device=device,dtype=dtype)==i0)[:,None]*(torch.arange(4,device=device,dtype=dtype)==j0)[None,:]).to(dtype)\n",
    "        if j0 == 3:\n",
    "            tosum0 = DW[...,i0]\n",
    "        else:\n",
    "            tosum0 = DW[...,i0]*XI[...,j0]\n",
    "            \n",
    "        count1 = 0\n",
    "        for i1 in range(3):\n",
    "            for j1 in range(4):\n",
    "                if count0 > count1:\n",
    "                    count1 += 1\n",
    "                    continue                                \n",
    "                E1 = ((torch.arange(4,device=device,dtype=dtype)==i1)[:,None]*(torch.arange(4,device=device,dtype=dtype)==j1)[None,:]).to(dtype)                \n",
    "                if j1 == 3:\n",
    "                    tosum1 = DW[...,i1]\n",
    "                else:\n",
    "                    tosum1 = DW[...,i1]*XI[...,j1]\n",
    "                                                            \n",
    "                gid[count0,count1] = torch.sum(tosum0*tosum1)*DI\n",
    "                gid[count1,count0] = gid[count0,count1]                                \n",
    "                \n",
    "                count1 += 1\n",
    "        count0 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_to_big(a):\n",
    "    '''\n",
    "    Convert A to a big linear map that acts on a vectorized matrix\n",
    "    We compute it through its action on basis vectors\n",
    "    '''\n",
    "    \n",
    "    A = torch.zeros(12,12,dtype=a.dtype,device=a.device)\n",
    "    device = a.device\n",
    "    dtype = a.dtype\n",
    "    count0 = 0\n",
    "    for i0 in range(3):\n",
    "        for j0 in range(4):\n",
    "            E0 = ((torch.arange(4,device=device,dtype=dtype)==i0)[:,None]*(torch.arange(4,device=device,dtype=dtype)==j0)[None,:]).to(dtype)\n",
    "            \n",
    "            A[:,count0] = (a@E0)[:3,:4].ravel()\n",
    "            count0 += 1\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gA_from_gid(gid,A):\n",
    "    # we need to convert A to a 12x12 map\n",
    "    A_ = small_to_big(torch.linalg.inv(A))\n",
    "    gA = A_.T@gid@A_\n",
    "    return gA    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use the inner product for the 2D affine\n",
    "\n",
    "# now we need to do the same for gJ\n",
    "# but these will change\n",
    "# so instead we'll just do this\n",
    "Jind = len(XJ)//2\n",
    "W_ = torch.ones_like(XJ[Jind][...,0])\n",
    "border = 2\n",
    "W_[:border] = 0.0\n",
    "W_[-border:] = 0.0\n",
    "W_[:,:border] = 0.0\n",
    "W_[:,-border:] = 0.0\n",
    "W_[:,:,:border] = 0.0\n",
    "W_[:,:,-border:] = 0.0\n",
    "\n",
    "\n",
    "DW = torch.stack(torch.gradient(W_,spacing=dI.tolist(),dim=(0,1,2)),-1)\n",
    "emlddmm.draw(DW.permute(-1,0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gJid = torch.zeros(12,12,device=device,dtype=dtype)\n",
    "\n",
    "count0 = 0\n",
    "for i0 in range(3):\n",
    "    for j0 in range(4):\n",
    "        E0 = ((torch.arange(4,device=device,dtype=dtype)==i0)[:,None]*(torch.arange(4,device=device,dtype=dtype)==j0)[None,:]).to(dtype)\n",
    "        if j0 == 3:\n",
    "            tosum0 = DW[...,i0]\n",
    "        else:\n",
    "            tosum0 = DW[...,i0]*XJ[Jind][...,j0]\n",
    "            \n",
    "        count1 = 0\n",
    "        for i1 in range(3):\n",
    "            for j1 in range(4):\n",
    "                if count0 > count1:\n",
    "                    count1 += 1\n",
    "                    continue                                \n",
    "                E1 = ((torch.arange(4,device=device,dtype=dtype)==i1)[:,None]*(torch.arange(4,device=device,dtype=dtype)==j1)[None,:]).to(dtype)                \n",
    "                if j1 == 3:\n",
    "                    tosum1 = DW[...,i1]\n",
    "                else:\n",
    "                    tosum1 = DW[...,i1]*XJ[Jind][...,j1]\n",
    "                                                            \n",
    "                gJid[count0,count1] = torch.sum(tosum0*tosum1)*DJs[Jind]\n",
    "                gJid[count1,count0] = gJid[count0,count1]                                \n",
    "                \n",
    "                count1 += 1\n",
    "        count0 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2)\n",
    "ax[0].imshow(gid.cpu())\n",
    "ax[1].imshow(gJid.cpu())\n",
    "\n",
    "# If the matrix were the identity, it would be identical to a Euclidean inner product\n",
    "# -- Accounts for differences in units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up kernels\n",
    "dv = torch.tensor([1.0,1.0,1.0],device=device,dtype=dtype)*500.0\n",
    "DV = torch.prod(dv)\n",
    "dI = torch.tensor(dI,device=device,dtype=dtype)\n",
    "v_expand_factor = 0.1\n",
    "a = 500.0\n",
    "p = 2.0\n",
    "aprefactor = 0.25\n",
    "nt = 5\n",
    "\n",
    "print(f'a scale is {a}')\n",
    "x0v = [x[0] - (x[-1]-x[0])*v_expand_factor for x in xI]\n",
    "x1v = [x[-1] + (x[-1]-x[0])*v_expand_factor for x in xI]\n",
    "xv = [torch.arange(x0,x1,d,device=device,dtype=dtype) for x0,x1,d in zip(x0v,x1v,dv)]\n",
    "nv = torch.tensor([len(x) for x in xv],device=device,dtype=dtype)\n",
    "XV = torch.stack(torch.meshgrid(xv),-1)\n",
    "\n",
    "# build energy operator for velocity\n",
    "fv = [torch.arange(n,device=device,dtype=dtype)/d/n for n,d in zip(nv,dv)]\n",
    "FV = torch.stack(torch.meshgrid(fv))\n",
    "\n",
    "LL = (1.0 - 2.0*a**2 * \n",
    "          ( (torch.cos(2.0*np.pi*FV[0]*dv[0]) - 1)/dv[0]**2  \n",
    "        + (torch.cos(2.0*np.pi*FV[1]*dv[1]) - 1)/dv[1]**2  \n",
    "        + (torch.cos(2.0*np.pi*FV[2]*dv[2]) - 1)/dv[2]**2   ) )**(p*2)\n",
    "K = 1.0/LL\n",
    "\n",
    "LLpre = (1.0 - 2.0*(aprefactor*torch.max(dI))**2 * \n",
    "         ( (torch.cos(2.0*np.pi*FV[0]*dv[0]) - 1)/dv[0]**2  \n",
    "         + (torch.cos(2.0*np.pi*FV[1]*dv[1]) - 1)/dv[1]**2  \n",
    "         + (torch.cos(2.0*np.pi*FV[2]*dv[2]) - 1)/dv[2]**2   ) )**(p*2)\n",
    "Kpre = 1.0/LLpre\n",
    "KK = K*Kpre\n",
    "\n",
    "# Define the spatial scale, following a form commonly used in the literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up kernels for blocks\n",
    "dvJ = torch.tensor([1.0,1.0,1.0],device=device,dtype=dtype)*100.0\n",
    "DVJ = torch.prod(dvJ)\n",
    "v_expand_factor = 0.1\n",
    "aJ = 50.0\n",
    "pJ = 2.0\n",
    "aprefactorJ = 0.25\n",
    "ntJ = 3\n",
    "\n",
    "print(f'aJ scale is {aJ}')\n",
    "LLJ = []\n",
    "KJ = []\n",
    "KJpre = []\n",
    "XVJ = []\n",
    "xvJ = []\n",
    "for i in range(len(J)):\n",
    "    x0vJ = [x[0] - (x[-1]-x[0])*v_expand_factor for x in xJs[i]]\n",
    "    x1vJ = [x[-1] + (x[-1]-x[0])*v_expand_factor for x in xJs[i]]    \n",
    "    xvJi = [torch.arange(x0,x1,d,device=device,dtype=dtype) for x0,x1,d in zip(x0vJ,x1vJ,dvJ)]\n",
    "    nvJi = torch.tensor([len(x) for x in xvJi],device=device,dtype=dtype)\n",
    "    XVJi = torch.stack(torch.meshgrid(xvJi),-1)\n",
    "\n",
    "    \n",
    "    \n",
    "    # build energy operator for velocity\n",
    "    fvJi = [torch.arange(n,device=device,dtype=dtype)/d/n for n,d in zip(nvJi,dvJ)]\n",
    "    FVJi = torch.stack(torch.meshgrid(fvJi))\n",
    "\n",
    "    LLJi = (1.0 - 2.0*aJ**2 * \n",
    "            ( (torch.cos(2.0*np.pi*FVJi[0]*dvJ[0]) - 1)/dvJ[0]**2  \n",
    "            + (torch.cos(2.0*np.pi*FVJi[1]*dvJ[1]) - 1)/dvJ[1]**2  \n",
    "            + (torch.cos(2.0*np.pi*FVJi[2]*dvJ[2]) - 1)/dvJ[2]**2   ) )**(pJ*2)\n",
    "    KJi = 1.0/LLJi\n",
    "\n",
    "    LLpreJi = (1.0 - 2.0*(aprefactorJ*torch.max(dI))**2 * \n",
    "             ( (torch.cos(2.0*np.pi*FVJi[0]*dvJ[0]) - 1)/dvJ[0]**2  \n",
    "             + (torch.cos(2.0*np.pi*FVJi[1]*dvJ[1]) - 1)/dvJ[1]**2  \n",
    "             + (torch.cos(2.0*np.pi*FVJi[2]*dvJ[2]) - 1)/dvJ[2]**2   ) )**(pJ*2)\n",
    "    KpreJi = 1.0/LLpreJi\n",
    "    KKJi = KJi*KpreJi\n",
    "\n",
    "    LLJ.append(LLJi)\n",
    "    KJ.append(KJi)\n",
    "    KJpre.append(KpreJi)\n",
    "    XVJ.append(XVJi)\n",
    "    xvJ.append(xvJi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Guess"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A[:2,:2] defines orientation via rotations (Every row + col should have a single +1 or -1)\n",
    "A[0,3]: +Val => Anterior, -Val => Posterior\n",
    "A[1,3]: +Val => Inferior, -Val => Superior\n",
    "A[2,3]: +Val => Left, -Val => Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize params (3D)\n",
    "\n",
    "# =================================================================\n",
    "# ===== Initialize A, TJ, and AJ to define image orientations =====\n",
    "# =================================================================\n",
    "if brain == '12m_MQC15-1':\n",
    "    A = torch.tensor([[-1.0,0.0,0.0,2500.0],\n",
    "                 [0.0,0.0,-1.0,200.0],\n",
    "                 [0.0,1.0,0.0,1800.0],\n",
    "                 [0.0,0.0,0.0,1.0]],device=device,dtype=dtype)\n",
    "else:\n",
    "    if orientation == 'W': # TME\n",
    "        A = torch.tensor([[-1.0,0.0,0.0,500.0],\n",
    "                         [0.0,0.0,-1.0,0.0],\n",
    "                         [0.0,1.0,0.0,0.0],\n",
    "                         [0.0,0.0,0.0,1.0]],device=device,dtype=dtype) \n",
    "    elif orientation == 'R': # */Q140_MORF/*\n",
    "        A = torch.tensor([[-1.0,0.0,0.0,1000.0],\n",
    "                     [0.0,0.0,-1.0,200.0],\n",
    "                     [0.0,1.0,0.0,-1800.0],\n",
    "                     [0.0,0.0,0.0,1.0]],device=device,dtype=dtype)\n",
    "    elif orientation == 'L': # */KO-Het/*\n",
    "        A = torch.tensor([[-1.0,0.0,0.0,1000.0],\n",
    "                     [0.0,0.0,-1.0,200.0],\n",
    "                     [0.0,1.0,0.0,1800.0],\n",
    "                     [0.0,0.0,0.0,1.0]],device=device,dtype=dtype) \n",
    "    else:\n",
    "        raise Exception(f'Invalid Orientation: {orientation}')\n",
    "\n",
    "# else:\n",
    "#     A = torch.tensor([[-1.0,0.0,0.0,500.0],\n",
    "#                  [0.0,0.0,-1.0,200.0],\n",
    "#                  [0.0,1.0,0.0,1800.0],\n",
    "#                  [0.0,0.0,0.0,1.0]],device=device,dtype=dtype)     \n",
    "    \n",
    "# For tme08, A and T must be centered to work with the trapezoid\n",
    "# - AJ must not be centered\n",
    "# note previously I used AJ inverse so it was easy to model flips\n",
    "# when I get flip info, I'll have to do some work\n",
    "# per slice, note translations \n",
    "# these take the slices and move them to be zero centered\n",
    "TJ = [torch.tensor([[1.0,0.0,0.0,-(i - (len(J)-1)/2.0)*dslice],\n",
    "                   [0.0,1.0,0.0,0.0],\n",
    "                   [0.0,0.0,1.0,0.0],\n",
    "                   [0.0,0.0,0.0,1.0]],device=device,dtype=dtype) for i in range(len(J))]\n",
    "\n",
    "AJ = [torch.tensor([[0.75,0.0,0.0,np.mean(xJs[i][0])], # 0.75 shrinks the slices, ensuring the edges don't exceed the volume boundaries\n",
    "                   [0.0,1.0,0.0,np.mean(xJs[i][1])],\n",
    "                   [0.0,0.0,1.0,np.mean(xJs[i][2])],\n",
    "                   [0.0,0.0,0.0,1.0]],device=device,dtype=dtype) for i in range(len(J))]\n",
    "\n",
    "AJ = torch.stack(AJ)\n",
    "\n",
    "# ===============================================================================\n",
    "# ===== Flip specific slabs, so all slabs within brain are same orientation =====\n",
    "# ===============================================================================\n",
    "\n",
    "# From the spreadsheet Chris sent\n",
    "to_flip = []\n",
    "if 'TME08-1' in brain:\n",
    "    to_flip = [0,1,3,5,7]\n",
    "elif 'TME10-1' in brain:\n",
    "    to_flip = [0,1,2,5,7,8]\n",
    "elif 'TME10-3' in brain:\n",
    "    to_flip = [1,3,7]\n",
    "elif 'TME12-1' in brain:\n",
    "    to_flip = [0,1,2,3,5,6,7]\n",
    "elif 'TME20-1' in brain:\n",
    "    to_flip = [0,1,4,8]\n",
    "elif 'Hpca5-2' in brain:\n",
    "    to_flip = [0,2]\n",
    "elif 'Sp9-3-2' in brain:\n",
    "    to_flip = [0] \n",
    "elif 'Trank1-2-3' in brain:\n",
    "    to_flip = []\n",
    "elif 'Zswim4-1' in brain:\n",
    "    to_flip = []\n",
    "elif 'MQC' in brain and '12m' not in brain:\n",
    "    to_flip = [0,1,2,3,4,5,6,7]\n",
    "elif 'TME07-1' in brain:\n",
    "    to_flip = [1,2,3,4,5]\n",
    "elif 'TME09-1' in brain:\n",
    "    to_flip = [0,1]\n",
    "elif 'hTME15-1' in brain:\n",
    "    to_flip = [0,1]\n",
    "elif 'hTME15-2' in brain:\n",
    "    to_flip = [5]\n",
    "elif 'hTME18-1' in brain:\n",
    "    to_flip = []\n",
    "elif 'hTME19-2' in brain:\n",
    "    to_flip = []\n",
    "elif '12m_MQC06-2' in brain:\n",
    "    to_flip = [0,1,2,3,4,5]\n",
    "elif '12m_MQC15-1' in brain:\n",
    "    to_flip = [0,1,2,3,4]\n",
    "elif '12m_MQC18-3' in brain:\n",
    "    to_flip = [0,1,2,3,4,5,6]\n",
    "elif '12m_MQC07-5' in brain:\n",
    "    to_flip = []\n",
    "elif '12m_MQC09-3' in brain:\n",
    "    to_flip = [0,1,3,4,5,6]\n",
    "elif '12m_MQC6-4' in brain:\n",
    "    to_flip = [0,1,2,3,4,5]\n",
    "\n",
    "# Perform the flips\n",
    "if to_flip != [] and brain != '12m_MQC18-3':\n",
    "    for i in range(AJ.shape[0]):\n",
    "        # I'd like to flip first and then shift\n",
    "        if i in to_flip:\n",
    "            AJ[i][0,0] = AJ[i][0,0]*(-1) # anterior-posterior flip\n",
    "            AJ[i][2,2] = AJ[i][2,2]*(-1) # left right flip\n",
    "    print(f'Flipped: {brain}')\n",
    "\n",
    "# 12m_MQC18-3 has one slab which requires different flips\n",
    "if brain == '12m_MQC18-3':\n",
    "    for i in range(AJ.shape[0]):\n",
    "        # I'd like to flip first and then shift\n",
    "        if i == 0:\n",
    "            AJ[i][1,1] = AJ[i][1,1]*(-1) # vertical flip\n",
    "            AJ[i][2,2] = AJ[i][2,2]*(-1) # left right flip            \n",
    "        if i in to_flip and i > 0:\n",
    "            AJ[i][0,0] = AJ[i][0,0]*(-1) # anterior-posterior flip\n",
    "            AJ[i][2,2] = AJ[i][2,2]*(-1) # left right flip\n",
    "    print(f'Flipped: {brain}')    \n",
    "\n",
    "v = torch.zeros((nt,XV.shape[0],XV.shape[1],XV.shape[2],XV.shape[3]),device=device,dtype=dtype,requires_grad=True)\n",
    "vJ = [torch.zeros((ntJ,KJ[i].shape[0],KJ[i].shape[1],KJ[i].shape[2],3),device=device,dtype=dtype,requires_grad=True) for i in range(len(J))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception('Check A matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Starts the optimization procedure\n",
    "\n",
    "A.requires_grad = True\n",
    "AJ.requires_grad = True\n",
    "v.requires_grad = True\n",
    "for vJi in vJ: vJi.requires_grad = True\n",
    "\n",
    "# Set to 2 while tweaking initial guess or to 500 when observing early optimization\n",
    "niter = 40000\n",
    "# niter = 500\n",
    "# niter = 2\n",
    "\n",
    "sigmaR = 1e6\n",
    "sigmaR = 1e4\n",
    "sigmaRJ = 1e3\n",
    "\n",
    "vstart = 2000\n",
    "vJstart = 5000\n",
    "\n",
    "scale_factor = 1\n",
    "if '12m' in brain:\n",
    "    scale_factor = 0.5\n",
    "\n",
    "# J: Each slice (Non-J: The whoel brain)\n",
    "eA = 2e-1*scale_factor\n",
    "eAJ = eA*5e-2*scale_factor # since this data is centered, use tme07\n",
    "ev = 1e-3*scale_factor\n",
    "evJ = 2e-5*scale_factor\n",
    "\n",
    "# with sigmaRJ smaller, we need evJ smaller\n",
    "# Level of regularization one each slice\n",
    "sigmaRJ = 2e2\n",
    "\n",
    "# this means I will draw on 0, 10, and log spacing (or sqrt)\n",
    "ndraw = 1\n",
    "its = np.arange(niter)\n",
    "test = np.log(its+1)\n",
    "test = (its+1)**0.5\n",
    "#test = (its+1)**0.75\n",
    "test /= test[ndraw]\n",
    "draws = np.diff(np.ceil(test)) > 0\n",
    "draws = np.concatenate((draws,[False]))\n",
    "draws[0] = True\n",
    "\n",
    "figv = plt.figure()\n",
    "figPhiI = plt.figure()\n",
    "figFPhiI = plt.figure()\n",
    "figErr = plt.figure()\n",
    "figJ = plt.figure()\n",
    "figJRecon = plt.figure()\n",
    "figRGB = plt.figure()\n",
    "figE,axE = plt.subplots(1,3)\n",
    "axE = axE.ravel()\n",
    "figP,axP = plt.subplots(2,3)\n",
    "axP = axP.ravel()\n",
    "Esave = []\n",
    "Lsave = []\n",
    "Tsave = []\n",
    "LJsave = []\n",
    "TJsave = []\n",
    "maxvsave = []\n",
    "maxvJsave = []\n",
    "\n",
    "# =========================================================\n",
    "# === Specify output directory for intermediate results ===\n",
    "# =========================================================\n",
    "outdir = f'dragonfly_outputs/{brain}/dragonfly_output_vis'\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "    \n",
    "for it in range(niter):\n",
    "    start = time.time()\n",
    "    # take the atlas and map it onto the slices\n",
    "    phiI = []\n",
    "    fphiI = []\n",
    "    coeffs = []\n",
    "    err = []\n",
    "    if draws[it]:#not it%ndraw:\n",
    "        Jrecon = torch.zeros_like(I[0][None])\n",
    "        Precon = torch.zeros_like(I[0])\n",
    "        \n",
    "    Ai = torch.linalg.inv(A)\n",
    "    EM = 0.0\n",
    "    E = 0.0\n",
    "    drawtime = 0.0\n",
    "    \n",
    "    # generate the single deformation\n",
    "    phii = torch.clone(XV)\n",
    "    for t in range(nt):\n",
    "        Xs = XV-v[t]/nt\n",
    "        phii = (emlddmm.interp(xv,(phii-XV).permute(-1,0,1,2),Xs.permute(-1,0,1,2))).permute(1,2,3,0) + Xs\n",
    "    # the energy\n",
    "    ER = torch.sum(torch.sum(torch.abs(torch.fft.fftn(v,dim=(1,2,3)))**2,dim=(0,-1))*LL)/np.prod(v.shape[1:4])*DV/2.0/sigmaR**2/nt\n",
    "    E += ER\n",
    "    ERJ = 0.0\n",
    "    for i in range(len(J)):\n",
    "        # 2d affine\n",
    "        AJi = torch.linalg.inv(AJ[i])\n",
    "        TJi = torch.linalg.inv(TJ[i])\n",
    "        TAJi = TJi@AJi\n",
    "        Xs = (AJi[:3,:3]@XJ[i][...,None])[...,0] + AJi[:3,-1]\n",
    "        \n",
    "        # now add the diffeomorphism\n",
    "        phiiJ = torch.clone(XVJ[i])\n",
    "        for t in range(ntJ):\n",
    "            Xs_ = XVJ[i]-vJ[i][t]/ntJ\n",
    "            phiiJ = (emlddmm.interp(xvJ[i],(phiiJ-XVJ[i]).permute(-1,0,1,2),Xs_.permute(-1,0,1,2))).permute(1,2,3,0) + Xs_\n",
    "        ERJ_ = torch.sum(torch.sum(torch.abs(torch.fft.fftn(vJ[i],dim=(1,2,3)))**2,dim=(0,-1))*LLJ[i])/np.prod(vJ[i].shape[1:4])*DVJ/2.0/sigmaRJ**2/ntJ\n",
    "        ERJ += ERJ_\n",
    "        E += ERJ_\n",
    "        \n",
    "        # where should I insert the diffeomorphism? I think it should be after Ai, before Ti\n",
    "        Xs = emlddmm.interp(xvJ[i],(phiiJ-XVJ[i]).permute(-1,0,1,2),Xs.permute(-1,0,1,2)).permute(1,2,3,0) + Xs\n",
    "        # now translate\n",
    "        Xs = (TJi[:3,:3]@Xs[...,None])[...,0] + TJi[:3,-1]\n",
    "        \n",
    "        # now evaluate the projection in this space\n",
    "        #P = torch.abs(  Xs[...,0] - (i - (len(J)-1)/2.0)*dslice) < dslice/2.0\n",
    "        P = trapezoid(Xs[...,0],i)\n",
    "        \n",
    "\n",
    "        # now 3D back to atlas\n",
    "        Xs = (Ai[:3,:3]@Xs[...,None])[...,0] + Ai[:3,-1]\n",
    "        # shape\n",
    "        Xs = emlddmm.interp(xv,(phii-XV).permute(-1,0,1,2),Xs.permute(-1,0,1,2)).permute(1,2,3,0)+Xs\n",
    "        # now interpolate\n",
    "        phiI_ = emlddmm.interp(xI,I,Xs.permute(-1,0,1,2))\n",
    "        phiI_ = phiI_*P\n",
    "        \n",
    "\n",
    "        # now we map contrast\n",
    "        phiI_r = phiI_.reshape(phiI_.shape[0],-1)\n",
    "        B = torch.cat( (torch.ones_like(phiI_r[0])[None],  phiI_r))\n",
    "        Ji = J[i]\n",
    "        Ji_r = Ji.reshape((Ji.shape[0],-1))        \n",
    "\n",
    "        # we also want to map them back, use P as a weight, or for now just add them\n",
    "        coeffs_ = torch.linalg.solve(B@(B*W[i].reshape(1,-1)).T + torch.eye(B.shape[0],device=device,dtype=dtype)*0.1,\n",
    "                                     (Ji_r@(B*W[i].reshape(1,-1)).T).T).T\n",
    "        coeffs.append(coeffs_)\n",
    "        fphiI_ = (coeffs_@B).reshape(Ji.shape)\n",
    "        \n",
    "        \n",
    "        err_ = (fphiI_ - J[i])\n",
    "        \n",
    "        EM += torch.sum(err_**2*W[i])*DJs[i]\n",
    "        E += EM\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "        # now let's contribute to Jrecon if I'm going to draw\n",
    "        if draws[it]:#not it%ndraw:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                start1 = time.time()\n",
    "                phiI.append(phiI_)\n",
    "                fphiI.append(fphiI_)\n",
    "                err.append(err_)\n",
    "            \n",
    "                # first calc phi\n",
    "                if i == 0:\n",
    "                    phi = torch.clone(XV)\n",
    "                    for t in reversed(range(nt)):\n",
    "                        Xs = XV+v[t]/nt\n",
    "                        phi = (emlddmm.interp(xv,(phi-XV).permute(-1,0,1,2),Xs.permute(-1,0,1,2))).permute(1,2,3,0) + Xs\n",
    "                    \n",
    "                # calculate phiJ\n",
    "                phiJ = torch.clone(XVJ[i])\n",
    "                for t in reversed(range(ntJ)):\n",
    "                    Xs = XVJ[i]+vJ[i][t]/ntJ\n",
    "                    phiJ = (emlddmm.interp(xvJ[i],(phiJ-XVJ[i]).permute(-1,0,1,2),Xs.permute(-1,0,1,2))).permute(1,2,3,0) + Xs\n",
    "                \n",
    "                \n",
    "                # diffeo                \n",
    "                Xs = emlddmm.interp(xv,(phi-XV).permute(-1,0,1,2),XI.permute(-1,0,1,2)).permute(1,2,3,0) + XI\n",
    "                # affine\n",
    "                Xs = (A[:3,:3]@Xs[...,None])[...,0] + A[:3,-1]\n",
    "                # translation T                \n",
    "                Xs = (TJ[i][:3,:3]@Xs[...,None])[...,0] + TJ[i][:3,-1]\n",
    "                # diffeo J\n",
    "                Xs = emlddmm.interp(xvJ[i],(phiJ-XVJ[i]).permute(-1,0,1,2),Xs.permute(-1,0,1,2)).permute(1,2,3,0) + Xs\n",
    "                # affine AJ\n",
    "                Xs = (AJ[i][:3,:3]@Xs[...,None])[...,0] + AJ[i][:3,-1]\n",
    "                # reconstruct\n",
    "                Jrecon += emlddmm.interp(xJ[i],J[i]*P,Xs.permute(-1,0,1,2),padding_mode='zeros')\n",
    "                Precon += emlddmm.interp(xJ[i],P[None],Xs.permute(-1,0,1,2),padding_mode='zeros')[0]\n",
    "                drawtime += time.time()-start1\n",
    "        \n",
    "    # other saved variables\n",
    "    Lsave.append( A[:3,:3].clone().detach().cpu().ravel().numpy() )\n",
    "    Tsave.append( A[:3,-1].clone().detach().cpu().ravel().numpy() )\n",
    "    LJsave.append(AJ[:,:3,:3].clone().detach().cpu().ravel().numpy())\n",
    "    TJsave.append(AJ[:,:3,-1].clone().detach().cpu().ravel().numpy())\n",
    "    \n",
    "    # gradient and update\n",
    "    Esave.append([E.item(),(E-ER).item(),ER.item(),ERJ.item()])\n",
    "    E.backward()\n",
    "    maxvsave.append(torch.max(torch.sqrt(torch.sum(v**2,-1))).item())\n",
    "    maxvJsave.append([torch.max(torch.sqrt(torch.sum(vJ[i]**2,-1))).item() for i in range(len(J))])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        gA = gA_from_gid(gid,A)\n",
    "        Agrad = torch.linalg.solve(gA,A.grad[:3].reshape(-1)).reshape(3,4)\n",
    "        \n",
    "        \n",
    "        \n",
    "        A[:3] -= eA*Agrad                        \n",
    "        A.grad.zero_()\n",
    "        \n",
    "        AJgrad = AJ.grad[:,:3]\n",
    "        \n",
    "        \n",
    "        for i in range(len(J)):\n",
    "            gJA = gA_from_gid(gJid,AJ[i])\n",
    "            AJgradi = torch.linalg.solve(gJA,AJgrad[i].reshape(-1)).reshape(3,4)\n",
    "            \n",
    "            AJ[i,:3] -= eAJ*AJgradi\n",
    "        AJ.grad.zero_()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # vgrad\n",
    "        if it >= vstart:\n",
    "            vgrad = v.grad\n",
    "            # we need to blur it (times Kpre?)        \n",
    "            vgrad = torch.fft.ifftn(torch.fft.fftn(vgrad,dim=(1,2,3))*((K*Kpre)[...,None]),dim=(1,2,3)).real\n",
    "            \n",
    "            v -= vgrad*ev\n",
    "        v.grad.zero_()\n",
    "        \n",
    "        for i in range(len(J)):\n",
    "            if it >= vJstart:\n",
    "                vJgrad = vJ[i].grad\n",
    "                # we need to blur it (times Kpre?)        \n",
    "                vJgrad = torch.fft.ifftn(torch.fft.fftn(vJgrad,dim=(1,2,3))*((KJ[i]*KJpre[i])[...,None]),dim=(1,2,3)).real\n",
    "                \n",
    "                vJ[i] -= vJgrad*evJ\n",
    "            vJ[i].grad.zero_()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    with torch.no_grad():\n",
    "        start1 = time.time()\n",
    "        if draws[it]:#not it%ndraw:        \n",
    "            Jrecon /= Precon\n",
    "            Jrecon[Precon[None]==0]=0\n",
    "            \n",
    "            toshow = [_.clone().detach().cpu() for _ in phiI]\n",
    "            _ = draw_stack(toshow,xJs,vmin=0.0,fig=figPhiI)\n",
    "            figPhiI.suptitle('phiI')\n",
    "            toshow = [_.clone().detach().cpu() for _ in fphiI]\n",
    "            _ = draw_stack(toshow,xJs,vmin=vminJ,vmax=vmaxJ,fig=figFPhiI)\n",
    "            figFPhiI.suptitle('fphiI')\n",
    "\n",
    "            toshow = [_.clone().detach().cpu() for _ in err]\n",
    "            _ = draw_stack(toshow,xJs,vmin=-vmaxJ*0.5,vmax=vmaxJ*0.5,fig=figErr)\n",
    "            figErr.suptitle('err')\n",
    "            if it == 0:\n",
    "                toshow = [_.clone().detach().cpu() for _ in J]\n",
    "                _ = draw_stack(toshow,xJs,vmin=vminJ,vmax=vmaxJ,fig=figJ)\n",
    "                figJ.suptitle('J')\n",
    "\n",
    "            _ = emlddmm.draw(Jrecon,xI,vmin=vminJ,vmax=vmaxJ,fig=figJRecon)\n",
    "            figJRecon.suptitle('Jrecon')\n",
    "            emlddmm.draw(torch.cat((I/torch.amax(I,dim=(1,2,3),keepdims=True)*0.5,(Jrecon-vminJ)/(vmaxJ-vminJ))),xI,vmin=0.0,vmax=1.0,fig=figRGB)\n",
    "            figRGB.suptitle('Jrecon and atlas')\n",
    "            \n",
    "            _ = emlddmm.draw(v[0].permute(-1,0,1,2),xv,fig=figv)\n",
    "            figv.suptitle('v0')\n",
    "            \n",
    "            axE[0].cla()\n",
    "            axE[0].plot(Esave)\n",
    "            axE[0].set_title('Energy')\n",
    "            axE[0].legend(['E','EM','ER','ERJ'])\n",
    "            axE[1].cla()\n",
    "            axE[1].plot([e[-2:] for e in Esave])\n",
    "            axE[1].set_title('Regularization only')\n",
    "            \n",
    "            axP[0].cla()\n",
    "            axP[0].plot(Lsave)\n",
    "            axP[0].set_title('L')\n",
    "            axP[1].cla()\n",
    "            axP[1].plot(Tsave)\n",
    "            axP[1].set_title('T')\n",
    "            axP[2].cla()\n",
    "            axP[2].plot(LJsave)\n",
    "            axP[2].set_title('LJ')\n",
    "            axP[3].cla()\n",
    "            axP[3].plot(TJsave)\n",
    "            axP[3].set_title('TJ')\n",
    "            axP[4].cla()\n",
    "            axP[4].plot(maxvsave)\n",
    "            axP[4].set_title('max v')\n",
    "            axP[5].cla()\n",
    "            axP[5].plot(maxvJsave)\n",
    "            axP[5].set_title('max vJ')\n",
    "            \n",
    "            figPhiI.canvas.draw()\n",
    "            figFPhiI.canvas.draw()\n",
    "            figErr.canvas.draw()\n",
    "            figJ.canvas.draw()\n",
    "            figJRecon.canvas.draw()\n",
    "            figRGB.canvas.draw()\n",
    "            figE.canvas.draw()\n",
    "            figP.canvas.draw()\n",
    "            figv.canvas.draw()\n",
    "            \n",
    "            # save in the outdir\n",
    "            figRGB.savefig(os.path.join(outdir,f'rgb_it_{it:05d}.jpg'))\n",
    "            figJRecon.savefig(os.path.join(outdir,f'recon_it_{it:05d}.jpg'))\n",
    "            #figRGB.savefig(os.path.join(outdir,f'rgb_it_{it:05d}.png'))\n",
    "            #figJRecon.savefig(os.path.join(outdir,f'recon_it_{it:05d}.png'))\n",
    "            drawtime += time.time() - start1\n",
    "            \n",
    "            print(f'drawing took {drawtime} s')\n",
    "    if not it%10:\n",
    "        print(f'Finished it {it} ({time.time() - start} s), E: {E.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception('STOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_stack([Ji.cpu() for Ji in J],xJs)\n",
    "draw_stack([Wi.cpu()[None] for Wi in W],xJs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emlddmm.draw(W[-3][None])\n",
    "emlddmm.draw(J[-3],vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig.canvas._get_output_canvas(None,'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phiI_r.shape,Ji_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ji_r.shape,W[i].reshape(1,-1).shape,B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emlddmm.write_data(join(outdir,'test0.vtk'),xI,Jrecon,'reconstructed')\n",
    "emlddmm.write_data(join(outdir,'test1.vtk'),xI,I,'atlas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xv = fillna(xv,2)\n",
    "# out = fillna(xvJ,3)\n",
    "# xvJ[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vJ_ = np.empty(len(vJ),object)\n",
    "vJ_[:] = [v_.clone().detach().cpu().numpy() for v_ in vJ]\n",
    "\n",
    "xv_ = np.empty(len(xv),object)\n",
    "xv_[:] = [x_.clone().detach().cpu().numpy() for x_ in xv]\n",
    "\n",
    "xvJ_ = np.empty(len(xvJ),object)\n",
    "xvJ_[:] = [[x.clone().detach().cpu().numpy() for x in xvJi] for xvJi in xvJ]\n",
    "\n",
    "np.savez(join(outdir,'transformation_outputs.npz'), \n",
    "        xv=xv_,\n",
    "        v=v.clone().detach().cpu().numpy(),\n",
    "        xvJ=xvJ_,\n",
    "        vJ=vJ_, # why can't I save this (ok fixed)\n",
    "        A=A.clone().detach().cpu().numpy(),\n",
    "        AJ=AJ.clone().detach().cpu().numpy(),\n",
    "        TJ=[t.clone().detach().cpu().numpy() for t in TJ],\n",
    "        dtype=object\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note\n",
    "# probably it would be nice to have a fixed translation \n",
    "# then a translation to optimize over\n",
    "# otherwise, the scale is affecting the position\n",
    "# which is not ideal\n",
    "# the fixed translation should be whatever is in the slicing, since the slicing is fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is some problem saving the above\n",
    "# if I can't get the above to work, I'll need to try something else\n",
    "# like saving them all as separate files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === END OF NECESSARY CODE ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('We are done, no need to execute any more cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T d1 tomato, M morph, E, there is mouse number and cage number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce my standard pictures with outlines (in atlas space)\n",
    "outdir = 'dragonfly_output_vis_v04'\n",
    "xJrecon,Jrecon,_,_ = emlddmm.read_data(join(outdir,'test0.vtk'))\n",
    "xI,I,_,_ = emlddmm.read_data(join(outdir,'test1.vtk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next is to transforom the high resolution data\n",
    "xS,S,title,names = emlddmm.read_data(seg_name)\n",
    "# we want to visuze the above with S\n",
    "labels = np.unique(S)\n",
    "RGB = np.zeros((3,S.shape[1],S.shape[2],S.shape[3]))\n",
    "colors = np.random.rand(len(labels),3)\n",
    "colors[0] = 0.0\n",
    "for i,l in enumerate(labels):\n",
    "    RGB[:,S[0]==l] = colors[i][...,None]\n",
    "fig,ax = emlddmm.draw(RGB)\n",
    "plt.subplots_adjust(wspace=0,hspace=0,right=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emlddmm.draw(Jrecon,xJrecon,vmin=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jt = Jrecon\n",
    "figopts = {'dpi':300,'quality':90}\n",
    "alpha = 0.5\n",
    "low = 0.22\n",
    "high = 1.0\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "n = 4\n",
    "slices = np.round(np.linspace(0,I.shape[1],n+2)[1:-1]).astype(int)\n",
    "for i in range(n):\n",
    "    ax = fig.add_subplot(3,n,i+1)    \n",
    "    \n",
    "    # get slices\n",
    "    RGB_ = RGB[:,slices[i]].transpose(1,2,0)\n",
    "    S_ = S[0,slices[i]]\n",
    "    Jt_ = np.copy(Jt[0,slices[i]])\n",
    "    #Jt_ -= np.quantile(Jt_,0.01)\n",
    "    Jt_ -= low\n",
    "    #Jt_ /= np.quantile(Jt_,0.99)\n",
    "    Jt_ /= (high-low)\n",
    "    # find boundaries\n",
    "    border = S_ != np.roll(S_,shift=1,axis=0)\n",
    "    border |= S_ != np.roll(S_,shift=-1,axis=0)\n",
    "    border |= S_ != np.roll(S_,shift=1,axis=1)\n",
    "    border |= S_ != np.roll(S_,shift=-1,axis=1)\n",
    "    \n",
    "    # draw\n",
    "    ax.imshow(alpha*border[...,None]*RGB_ + ((1-alpha*border)*Jt_)[...,None])\n",
    "    if i>0:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "slices = np.round(np.linspace(0,I.shape[2],n+2)[1:-1]).astype(int)\n",
    "for i in range(n):\n",
    "    ax = fig.add_subplot(3,n,i+1 + n)    \n",
    "    \n",
    "    # get slices\n",
    "    RGB_ = RGB[:,:,slices[i]].transpose(1,2,0)\n",
    "    S_ = S[0,:,slices[i]]\n",
    "    Jt_ = np.copy(Jt[0,:,slices[i]])\n",
    "    # for this example quantiles are not so good\n",
    "    #Jt_ -= np.quantile(Jt_,0.01)\n",
    "    Jt_ -= low\n",
    "    #Jt_ /= np.quantile(Jt_,0.99)\n",
    "    Jt_ /= (high-low)\n",
    "    \n",
    "    # find boundaries\n",
    "    border = S_ != np.roll(S_,shift=1,axis=0)\n",
    "    border |= S_ != np.roll(S_,shift=-1,axis=0)\n",
    "    border |= S_ != np.roll(S_,shift=1,axis=1)\n",
    "    border |= S_ != np.roll(S_,shift=-1,axis=1)\n",
    "    \n",
    "    # draw\n",
    "    ax.imshow(alpha*border[...,None]*RGB_ + ((1-alpha*border)*Jt_)[...,None])\n",
    "    if i>0:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "slices = np.round(np.linspace(0,I.shape[3],n+2)[1:-1]).astype(int)\n",
    "for i in range(n):\n",
    "    ax = fig.add_subplot(3,n,i+1 + n+n)    \n",
    "    \n",
    "    # get slices\n",
    "    RGB_ = RGB[:,:,:,slices[i]].transpose(1,2,0)\n",
    "    S_ = S[0,:,:,slices[i]]\n",
    "    Jt_ = np.copy(Jt[0,:,:,slices[i]])\n",
    "    #Jt_ -= np.quantile(Jt_,0.01)\n",
    "    Jt_ -= low\n",
    "    #Jt_ /= np.quantile(Jt_,0.99)\n",
    "    Jt_ /= (high-low)\n",
    "    \n",
    "    # find boundaries\n",
    "    border = S_ != np.roll(S_,shift=1,axis=0)\n",
    "    border |= S_ != np.roll(S_,shift=-1,axis=0)\n",
    "    border |= S_ != np.roll(S_,shift=1,axis=1)\n",
    "    border |= S_ != np.roll(S_,shift=-1,axis=1)\n",
    "    \n",
    "    # draw\n",
    "    ax.imshow(alpha*border[...,None]*RGB_ + ((1-alpha*border)*Jt_)[...,None])    \n",
    "    if i>0:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "fig.suptitle('Atlas space')\n",
    "fig.subplots_adjust(wspace=0,hspace=0,left=0.0,right=1,bottom=0,top=0.95)\n",
    "makedirs(os.path.split(output_prefix)[0],exist_ok=True)\n",
    "fig.savefig(output_prefix+'atlas_space.jpg',**figopts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emlddmm.draw(Jt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
