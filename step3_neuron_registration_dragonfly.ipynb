{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "In neuron test v02, the plan is to use a single low res slice, and register data from its corresponding high res slices.\n",
    "\n",
    "For now I'm doing all the slices separately.\n",
    "\n",
    "In v03 I transform neurons into the big space as well.\n",
    "\n",
    "Next step in v04 will be to combine all the slices together with the atlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "in version 07 we need to fix the flat neuron outputs\n",
    "\n",
    "Note I have put the original from chris park here\n",
    "/home/dtward/bmaproot/nafs/dtward/dong/dragonfly_tme07_neurons\n",
    "\n",
    "and the latest\n",
    "/home/dtward/bmaproot/nafs/dtward/dong/dragonfly_tme07_neurons/updated_coords\n",
    "\n",
    "then we can deal with the new atlas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in v08 we have the new atlas and have output to csv\n",
    "\n",
    "we are working on fuzzy labels and double checking connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that in tme08, neurons are somewhere else\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# %matplotlib notebook\n",
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import split,join,splitext,basename\n",
    "from os import makedirs, listdir\n",
    "from glob import glob\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection, Line3DCollection\n",
    "from matplotlib.collections import PolyCollection, LineCollection\n",
    "from os import walk\n",
    "from skimage import measure\n",
    "\n",
    "from sys import path\n",
    "# path.append('/home/dtward/data/csh_data/emlddmm')\n",
    "path.append('/home/abenneck')\n",
    "from emlddmm import emlddmm\n",
    "from os import makedirs\n",
    "path.append('..')\n",
    "import donglab_workflows as dw\n",
    "\n",
    "path.append('panfs/dong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we have a backup unpickler that ignores figures in case there are version issues\n",
    "import pickle\n",
    "import subprocess\n",
    "from numpy.lib.format import read_magic, _check_version, _read_array_header\n",
    "class ClassHack:\n",
    "    '''\n",
    "    This class provides methods that my unpickling requires, but\n",
    "doesn't do anything\n",
    "    '''\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        pass\n",
    "    def __call__(*args,**kwargs):\n",
    "        pass\n",
    "    def _remove_ax(self,*args,**kwargs):\n",
    "        pass\n",
    "    def _remove_legend(self,*args,**kwargs):\n",
    "        pass\n",
    "    def delaxes(self,*args,**kwargs):\n",
    "        pass\n",
    "    def _key_handler(self,*args,**kwargs):\n",
    "        pass\n",
    "    def pick(self,*args,**kwargs):\n",
    "        pass\n",
    "class Unpickler(pickle.Unpickler):\n",
    "    '''\n",
    "    An unpickler which can ignore old matplotlib figures stored in a dictionary\n",
    "    '''\n",
    "    def find_class(self, module, name):\n",
    "        #print(module,name)\n",
    "        if name == 'CallbackRegistry':\n",
    "            #print('found callback registry')\n",
    "            return ClassHack\n",
    "        elif name == 'AxesStack':\n",
    "            #print('found axes stack')\n",
    "            return ClassHack\n",
    "        elif name == '_picklable_subplot_class_constructor':\n",
    "            #print('found subplot class constructor')\n",
    "            return ClassHack\n",
    "        elif module == 'matplotlib.figure' and name == 'Figure':\n",
    "            return ClassHack    \n",
    "        elif module =='matplotlib.backend_bases':\n",
    "            return ClassHack\n",
    "        else:\n",
    "            #print('normal module name')\n",
    "            return super().find_class(module,name)\n",
    "def backup_unpickle(reg_file)        :\n",
    "    output = subprocess.run(['unzip','-o',reg_file],capture_output=True)\n",
    "    with open('out.npy','rb') as f:\n",
    "        version = read_magic(f)\n",
    "        _check_version(version)\n",
    "        dtype = _read_array_header(f, version)[2]    \n",
    "        out = Unpickler(f).load().item()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_swc(fname,skip=0):\n",
    "    ''' load an swc file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        A string pointing to the file to load\n",
    "    skip : int\n",
    "        Number of lines to skip at the beginning. (default 0)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    V : numpy array of float\n",
    "        An array storing vertices\n",
    "    E : numpy array of int\n",
    "        An array storing edges.  they are ordered as parent -> this sample\n",
    "    R : numpy array of float\n",
    "        An arrow storing radii\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Instead, a folder containing fname is passed\n",
    "    # print(f'fname before: {fname}')\n",
    "    # if '.swc' not in fname:\n",
    "    #     for file in os.listdir(fname):\n",
    "    #         if '.swc' in file:\n",
    "    #             fname = os.path.join(fname,file)\n",
    "    #             print(f'fname during: {fname}')\n",
    "    #             break\n",
    "    # print(f'fname after: {fname}')\n",
    "        \n",
    "    \n",
    "    # load an swc\n",
    "    # recall columns\n",
    "    # data type, sample number, structure identifier, x,y,z,r,parent\n",
    "    v = {}\n",
    "    e = []\n",
    "    r = {}\n",
    "    with open(fname,'rt') as f:\n",
    "        for i,line in enumerate(f):\n",
    "            #print(line)\n",
    "            if i < skip:\n",
    "                continue\n",
    "                \n",
    "            #print(line)\n",
    "            data = line.split()\n",
    "            # may be comma separated\n",
    "            if len(data)==1:\n",
    "                data = line.split(',')\n",
    "            sample_number = int(data[0])\n",
    "            x = float(data[2])\n",
    "            y = float(data[3])\n",
    "            z = float(data[4])\n",
    "            r_ = float(data[5])\n",
    "            v[sample_number] = np.array([x,y,z])\n",
    "            r[sample_number] = np.array(r_)\n",
    "\n",
    "            par = int(data[-1])\n",
    "            if par >= 0:\n",
    "                #e.append([par,sample_number,])\n",
    "                e.append([par-1,sample_number-1,]) # move to zero indexing\n",
    "                pass\n",
    "    # we want to put v into a numpy array\n",
    "    maxkey = np.max([k for k in v])\n",
    "    V = np.ones((maxkey,3))*np.nan\n",
    "    for key in v:                \n",
    "        V[key-1] = v[key] # zero indexing\n",
    "    R = np.ones((maxkey,))*np.nan\n",
    "    for key in r:\n",
    "        R[key-1] = r[key] # zero indexing\n",
    "    E = np.array(e)\n",
    "    return V,E,R "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define Paths for Yang Images, Transform Outputs, & 10_to_30 Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update the brain to be processed\n",
    "# brain = 'TME07-1'\n",
    "brain = 'TME08-1'\n",
    "# brain = 'TME09-1'\n",
    "# brain = 'TME10-1'\n",
    "# brain = 'TME10-3'\n",
    "# brain = 'TME12-1'\n",
    "# brain = 'TME20-1'\n",
    "# brain = 'Hpca5-2'\n",
    "# brain = 'Sp9-3-2'\n",
    "# brain = 'Trank1-2-3'\n",
    "# brain = 'Zswim4-1'\n",
    "# brain = 'MQC06-2'\n",
    "# brain = 'MQC09-3'\n",
    "# brain = 'MQC18-3'\n",
    "# brain = 'MQC82-2'\n",
    "# brain = 'hTME15-1'\n",
    "# brain = 'hTME15-2'\n",
    "# brain = 'hTME18-1'\n",
    "# brain = 'hTME19-2'\n",
    "# brain = '12m_MQC06-2'\n",
    "# brain = '12m_MQC15-1'\n",
    "# brain = '12m_MQC18-3'\n",
    "# brain = '12m_MQC07-5'\n",
    "# brain = '12m_MQC09-3'\n",
    "# brain = '12m_MQC6-4'\n",
    "\n",
    "# Defines location of data (Needed if raw data is in subdirectory)\n",
    "if brain in ['TME08-1', 'TME10-1', 'TME10-3', 'TME12-1', 'TME20-1', 'TME07-1', 'TME09-1']:\n",
    "    brain_path = brain\n",
    "elif brain in ['MQC06-2', 'MQC09-3', 'MQC18-3', 'MQC82-2']: # The original HD brains\n",
    "    brain_path = f'Q140_MORF/{brain}'\n",
    "elif '12m' in brain: # The new HD brains\n",
    "    if '06-2' in brain or '15-1' in brain or '18-3' in brain:\n",
    "        brain_path = f'Q140_MORF/Shasha_Q140/Camk-MORF3_{brain}'\n",
    "    elif '07-5' in brain or '09-3' in brain:\n",
    "        brain_path = f'Q140_MORF/Shasha_Q140/Camk-MORF3-Q140_{brain}'\n",
    "    elif '6-4' in brain:\n",
    "        brain_path = f'Q140_MORF/Shasha_Q140/Camk-MORF3-Q140_12m_MQC6-4 (prev 6-3)_downsampled'\n",
    "    else:\n",
    "        raise Exception('Invalid brain')\n",
    "elif 'hTME' in brain:\n",
    "    if 'hTME15-1' in brain or 'hTME19-2' in brain:\n",
    "        brain_path = f'Q140_MORF_D1/Camk-MORF3-D1Tom_12m_{brain}'\n",
    "    elif 'hTME15-2' in brain or 'hTME18-1' in brain:\n",
    "        brain_path = f'Q140_MORF_D1/Camk-MORF3-D1Tom-Q140_12m_{brain}'\n",
    "    else:\n",
    "        raise Exception('Invalid brain')\n",
    "else: # KO-Het_MORF\n",
    "    if 'Hpca' in brain:\n",
    "        brain_path = f'KO-Het_MORF/HpcaKO-Camk-MORF3-D1tom_Hpca5-2'\n",
    "    elif 'Sp9' in brain:\n",
    "        brain_path = f'KO-Het_MORF/Sp9Het-Camk-MORF3-D1tom_Sp9-3-2'\n",
    "    elif 'Trank' in brain:\n",
    "        brain_path = f'KO-Het_MORF/Trank1KO-Camk-MORF3-D1tom_Trank1-2-3'\n",
    "    elif 'Zswim' in brain:\n",
    "        brain_path = f'KO-Het_MORF/Zswim6Het-Camk-MORF3-D1tom_Zswim4-1'\n",
    "    else:\n",
    "        raise Exception('Invalid brain')\n",
    "\n",
    "# Path to directory containing (.swc) files for all neurons associated with this brain\n",
    "if 'TME12-1' in brain:\n",
    "    neuron_dir = f'/panfs/dong/3D_registration/Yang_MORF_DragonFly/{brain_path}_recontructions'   \n",
    "elif 'TME07-1' in brain:\n",
    "    neuron_dir = f'/nafs/dtward/dong/dragonfly_tme07_neurons/updated_coords'\n",
    "else:\n",
    "    neuron_dir = f'/panfs/dong/3D_registration/Yang_MORF_DragonFly/{brain_path}_reconstructions'\n",
    "\n",
    "# Path to directory containing all microscopy images associated with this brain\n",
    "if 'TME07-1' in brain:\n",
    "    image_dir = '/nafs/dtward/dong/dragonfly_03_2022'\n",
    "else:\n",
    "    image_dir = f'/panfs/dong/3D_registration/Yang_MORF_DragonFly/{brain_path}_downsampled'\n",
    "\n",
    "# Path to directory containing all 10x to 30x transforms (.npz files) associated with this brain\n",
    "reg_dir = f'/home/abenneck/dragonfly_work/dragonfly_outputs/{brain}/dragonfly_10_to_30_outputs'\n",
    "\n",
    "# File path for the 10x to atlas transform (.npz file) associated with this brain\n",
    "transform_file = f'/home/abenneck/dragonfly_work/dragonfly_outputs/{brain}/dragonfly_output_vis/transformation_outputs.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Atlas Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load atlas images\n",
    "# atlas_names = [\n",
    "#     '/home/dtward/data/AllenInstitute/allen_vtk/ara_nissl_50.vtk',\n",
    "#     '/home/dtward/data/AllenInstitute/allen_vtk/average_template_50.vtk',\n",
    "# ]\n",
    "\n",
    "atlas_names = [\n",
    "    '/nafs/dtward/allen_vtk/allen_vtk/ara_nissl_50.vtk',\n",
    "    '/nafs/dtward/allen_vtk/allen_vtk/average_template_50.vtk',\n",
    "]\n",
    "\n",
    "# seg_name = '/home/dtward/mounts/bmaproot/nafs/dtward/dong/upenn_atlas/UPenn_labels_reoriented_origin.vtk'\n",
    "seg_name = '/nafs/dtward/dong/upenn_atlas/UPenn_labels_reoriented_origin.vtk'\n",
    "ontology_name = '/nafs/dtward/dong/upenn_atlas/atlas_info_KimRef_FPbasedLabel_v2.7.csv'\n",
    "\n",
    "# channel for 10 to 30 reg\n",
    "channel_10_to_30 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = f'/home/abenneck/dragonfly_work/dragonfly_outputs/{brain}/dragonfly_joint_outputs'\n",
    "makedirs(output_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_low_files = glob(join(image_dir,'*10x*channel_1_down.npz'))\n",
    "#image_low_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we need to walk through the dir to get the files\n",
    "image_low_files = []\n",
    "for dirpath, dirnames, filenames in walk(image_dir):\n",
    "    if 'TME07-1' in brain:\n",
    "        files = glob(join(dirpath,f'*10x*channel_{channel_10_to_30}*.npz'))\n",
    "    elif brain in ['MQC06-2', 'MQC09-3', 'MQC82-3', '12m_MQC15-1', '12m_MQC09-3'] or 'hTME' in brain:\n",
    "        files = glob(join(dirpath,f'*10X*ch_{channel_10_to_30}*.npz'))\n",
    "    elif '12m' in brain:\n",
    "        target_pattern_0 = f'*10X*_ch_{channel_10_to_30}*.npz'\n",
    "        target_pattern_1 = f'*10x*_ch_{channel_10_to_30}*.npz'\n",
    "        if len(glob(join(dirpath,target_pattern_0))) != 0:\n",
    "            files = glob(join(dirpath,target_pattern_0))\n",
    "        elif len(glob(join(dirpath,target_pattern_1))) != 0:\n",
    "            files = glob(join(dirpath,target_pattern_1))       \n",
    "    else:\n",
    "        files = glob(join(dirpath,f'*10x*ch_{channel_10_to_30}*.npz'))\n",
    "    image_low_files.extend(files)\n",
    "image_low_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_low_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transformations\n",
    "dataat = np.load(transform_file,allow_pickle=True)\n",
    "print([k for k in dataat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load segmentation\n",
    "xS,S,title,names = emlddmm.read_data(seg_name, normalize=False)\n",
    "dS = np.array([x[1]-x[0] for x in xS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# downsample segmentation\n",
    "xSd,Sd = emlddmm.downsample_image_domain(xS,(S>0)*1.0,[5,5,5])\n",
    "dSd = [x[1] - x[0] for x in xSd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create isosurface of segmentation\n",
    "verts,faces,normals,values = measure.marching_cubes((Sd[0]>0)*1.0,level=0.5)\n",
    "verts *= dSd # for 100 micron\n",
    "verts += np.array((xSd[0][0],xSd[1][0],xSd[2][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ontology\n",
    "ontology = {}\n",
    "import csv\n",
    "with open(ontology_name) as f:\n",
    "    reader = csv.reader(f)    \n",
    "    for count,row in enumerate(reader):\n",
    "        if count == 0:\n",
    "            headers = row\n",
    "            id_ind = 0\n",
    "            name_ind = headers.index('name')\n",
    "            acronym_ind = headers.index('acronym')\n",
    "            parent_ind = headers.index('parent_id')\n",
    "            continue\n",
    "        id_ = row[id_ind]\n",
    "        id_ = int(id_)\n",
    "        name = row[name_ind]\n",
    "        acronym = row[acronym_ind]\n",
    "        \n",
    "        parent = row[parent_ind]\n",
    "        if parent:\n",
    "            parent = int(parent)\n",
    "        else:\n",
    "            parent = None\n",
    "        ontology[id_] = dict(id=id_,name=name,acronym=acronym,parent=parent)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all labels corresponding to CP\n",
    "cp_ids = []\n",
    "for id_ in ontology:    \n",
    "    if 'caudoputamen' in ontology[id_]['name'].lower():\n",
    "        cp_ids.append(id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Iat = []\n",
    "for atlas_name in atlas_names:\n",
    "    xIat,I_,title,names = emlddmm.read_data(atlas_name)\n",
    "    I_ = I_.astype(np.float32)\n",
    "    I_ /= np.mean(np.abs(I_))\n",
    "    Iat.append(I_)\n",
    "    \n",
    "Iat = np.concatenate(Iat)   \n",
    "Iat[0] = Iat[0]**0.25\n",
    "Iat[0] /= np.mean(np.abs(Iat[0]))\n",
    "dIat = np.array([x[1] - x[0] for x in xIat])\n",
    "XIat = np.stack(np.meshgrid(*xIat,indexing='ij'),0)\n",
    "\n",
    "fig,ax = emlddmm.draw(Iat,xIat,vmin=0,n_slices=8)\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect data for one slab only to test new neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_ind = 7\n",
    "\n",
    "# load the low res image\n",
    "image_low_file = image_low_files[low_ind]\n",
    "if 'MQC' in brain or 'KO' in brain_path:\n",
    "    image_low_key = image_low_file.split('_')[-9]\n",
    "else:\n",
    "    image_low_key = image_low_file.split('_')[-6]\n",
    "    \n",
    "data = np.load(image_low_file,allow_pickle=True)\n",
    "I = data['I']\n",
    "\n",
    "# We decided to ignore voxel positions and use zero-mean convention b/c it is more numerically stable\n",
    "xI = [d - np.mean(d) for d in data['xI']]\n",
    "\n",
    "if len(xI[-1]) != I.shape[-1]:\n",
    "    # add one to the end\n",
    "    xI[-1] = np.concatenate((xI[-1],xI[-1][-1][None] + (xI[-1][1]-xI[-1][0])))\n",
    "    \n",
    "XI = np.stack(np.meshgrid(*xI,indexing='ij'))\n",
    "# sometimes, I and xI do not match in size!\n",
    "key = 'W' if 'W' in data else 'w'\n",
    "WI = data[key]\n",
    "dI = [xi[1] - xi[0] for xi in xI]\n",
    "# get extent and draw it\n",
    "extentlow0 = (xI[-1][0]-dI[-1],xI[-1][-1]+dI[-1],xI[-2][-1]+dI[-2],xI[-2][0]-dI[-2])\n",
    "extentlow1 = (xI[-2][0]-dI[-2],xI[-2][-1]+dI[-2],xI[-3][-1]+dI[-3],xI[-3][0]-dI[-3])\n",
    "extentlow2 = (xI[1][0]-dI[1],xI[1][-1]+dI[1],xI[0][-1]+dI[0],xI[0][0]-dI[0])\n",
    "I0 = np.max(I,0)\n",
    "I1 = np.max(I,1)\n",
    "I2 = np.max(I,2)\n",
    "fig,ax = plt.subplots()\n",
    "vminI = np.quantile(I[WI>0.999],0.1)\n",
    "vmaxI = np.quantile(I[WI>0.999],0.999)\n",
    "ax.imshow(I0,extent=extentlow0,vmin=vminI,vmax=vmaxI)\n",
    "ax.set_title(splitext(split(image_low_file)[-1])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_low_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now we find the corresponding high res files\n",
    "#image_high_files = glob(join(image_dir,'*30x_*' + image_low_key + '*_channel_0_down.npz'))\n",
    "## there should be two\n",
    "#image_high_keys = [n.split('_')[-4] for n in image_high_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_low_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_filter(x):\n",
    "    if 'cropped' in x or 'Cropped' in x or 'neurite' in x:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# again we need to walk\n",
    "# I want ch_1, but I'm stuck wiht 0 for now\n",
    "# really? I think for tme08 I want 0 but I'm stuck with 1\n",
    "# note this is what image I load, not which transform\n",
    "channel = channel_10_to_30\n",
    "#channel = 1 # nicer looking images\n",
    "image_high_files = []\n",
    "for dirpath, dirnames, filenames in walk(image_dir):\n",
    "    if 'TME07-1' in brain:\n",
    "        files = glob(join(dirpath,f'*{image_low_key}*30x*channel_{channel}*.npz'))\n",
    "    elif 'MQC' in brain:\n",
    "        files = glob(join(dirpath,f'*30X*{image_low_key}*ch_{channel}*.npz'))\n",
    "    else:\n",
    "        files = glob(join(dirpath,f'*30x*{image_low_key}*ch_{channel}*.npz'))\n",
    "    image_high_files.extend(files)\n",
    "image_high_files.sort()\n",
    "\n",
    "# NOTE: There are some files called \"cropped\" I don't want them\n",
    "# Note from Andrew: Some files also called 'Cropped' and 'neurite'\n",
    "# image_high_files = list(filter(lambda x: 'cropped' and 'Cropped' not in x, image_high_files))\n",
    "# image_high_files = list(filter(lambda x: 'cropped' and 'Cropped' and 'neurite' not in x, image_high_files))\n",
    "image_high_files = list(filter(temp_filter, image_high_files))\n",
    "\n",
    "image_high_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of all high res files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_high_files = []\n",
    "\n",
    "for dirpath, dirnames, filenames in walk(image_dir):\n",
    "    if 'TME07-1' in brain:\n",
    "        files = glob(join(dirpath,f'*{image_low_key}*30x*channel_{channel}*.npz'))\n",
    "    elif 'MQC' in brain:\n",
    "        files = glob(join(dirpath,f'*30X*{image_low_key}*ch_{channel}*.npz'))\n",
    "    else:\n",
    "        files = glob(join(dirpath,f'*30x*{image_low_key}*ch_{channel}*.npz'))\n",
    "    all_image_high_files.extend(files)\n",
    "all_image_high_files.sort()\n",
    "\n",
    "all_image_high_files = list(filter(lambda x: 'cropped' and 'Cropped' not in x, all_image_high_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_high_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that Voxel Locations == Number of Voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "Js = []\n",
    "xJs = []\n",
    "Ws = []\n",
    "dJs = []\n",
    "DJs = []\n",
    "print('Low res files')\n",
    "for fname in image_low_files:\n",
    "    print(fname)\n",
    "    data = np.load(fname,allow_pickle=True)\n",
    "    Js.append(data['I'][None])    \n",
    "\n",
    "    # We decided to ignore voxel positions and use zero-mean convention b/c it is more numerically stable\n",
    "    xJs.append([d-np.mean(d) for d in data['xI']])\n",
    "\n",
    "    if 'W' in data or 'w' in data:\n",
    "        if 'W' in data:\n",
    "            key = 'W'\n",
    "        else:\n",
    "            key = 'w'\n",
    "        W_ = data[key]\n",
    "        if W_.ndim == 4:\n",
    "            W_ = W_[0]\n",
    "        Ws.append(W_)\n",
    "    else:\n",
    "        #Ws.append(np.zeros_like(Js[0]))\n",
    "        # I think this should be ones\n",
    "        Ws.append(np.ones_like(Js[0]))\n",
    "    \n",
    "    \n",
    "    # we need to normalize to [0,1]\n",
    "    mymin = np.quantile(Js[-1][Ws[-1][None]>0.99],0.05)\n",
    "    mymax = np.quantile(Js[-1][Ws[-1][None]>0.99],0.99)\n",
    "    #print(mymin,mymax)\n",
    "    Js[-1] = (Js[-1] - mymin)/(mymax - mymin)\n",
    "    \n",
    "    # I'd like to squash the bright signal\n",
    "    signJ = np.sign(Js[-1])\n",
    "    Js[-1] = signJ*abs(Js[-1])**0.25\n",
    "\n",
    "    \n",
    "    # we need to normalize to [0,1] again!\n",
    "    mymin = np.quantile(Js[-1][Ws[-1][None]>0.99],0.05)\n",
    "    mymax = np.quantile(Js[-1][Ws[-1][None]>0.99],0.99)\n",
    "    #print(mymin,mymax)\n",
    "    Js[-1] = (Js[-1] - mymin)/(mymax - mymin)\n",
    "    # after scaling I'm going to zero out the low signals (new feb 2 2023)\n",
    "    Js[-1][Js[-1]<0.0] = 0.0\n",
    "    # also I think the weights are not strong enough\n",
    "    Ws[-1][Ws[-1]<0.999] = 0.0\n",
    "    \n",
    "    dJs.append([x[1]-x[0] for x in xJs[-1]])\n",
    "    DJs.append(np.prod(dJs[-1]) )\n",
    "    \n",
    "    # note, sometimes xJs don't match Js\n",
    "    s = -1\n",
    "    if len(xJs[-1][s]) != Js[-1].shape[s]:\n",
    "        print('mismatch')\n",
    "        print(f'x size {len(xJs[-1][s])} doesn\\'t match J size {Js[-1].shape[s]}')\n",
    "        n = Js[-1].shape[s] - len(xJs[-1][s]) \n",
    "        d = xJs[-1][s][1] - xJs[-1][s][0]\n",
    "        xJs[-1][s] = np.concatenate((xJs[-1][s],[xJs[-1][s][-1]+d ]))\n",
    "\n",
    "Js = []\n",
    "xJs = []\n",
    "Ws = []\n",
    "dJs = []\n",
    "DJs = []\n",
    "print('\\nHigh res files')\n",
    "for fname in all_image_high_files:\n",
    "    print(fname)\n",
    "    data = np.load(fname,allow_pickle=True)\n",
    "    Js.append(data['I'][None])    \n",
    "\n",
    "    # We decided to ignore voxel positions and use zero-mean convention b/c it is more numerically stable\n",
    "    xJs.append([d-np.mean(d) for d in data['xI']])\n",
    "    \n",
    "    if 'W' in data or 'w' in data:\n",
    "        if 'W' in data:\n",
    "            key = 'W'\n",
    "        else:\n",
    "            key = 'w'\n",
    "        W_ = data[key]\n",
    "        if W_.ndim == 4:\n",
    "            W_ = W_[0]\n",
    "        Ws.append(W_)\n",
    "    else:\n",
    "        #Ws.append(np.zeros_like(Js[0]))\n",
    "        # I think this should be ones\n",
    "        Ws.append(np.ones_like(Js[0]))\n",
    "    \n",
    "    \n",
    "    # we need to normalize to [0,1]\n",
    "    mymin = np.quantile(Js[-1][Ws[-1][None]>0.99],0.05)\n",
    "    mymax = np.quantile(Js[-1][Ws[-1][None]>0.99],0.99)\n",
    "    #print(mymin,mymax)\n",
    "    Js[-1] = (Js[-1] - mymin)/(mymax - mymin)\n",
    "    \n",
    "    # I'd like to squash the bright signal\n",
    "    signJ = np.sign(Js[-1])\n",
    "    Js[-1] = signJ*abs(Js[-1])**0.25\n",
    "\n",
    "    \n",
    "    # we need to normalize to [0,1] again!\n",
    "    mymin = np.quantile(Js[-1][Ws[-1][None]>0.99],0.05)\n",
    "    mymax = np.quantile(Js[-1][Ws[-1][None]>0.99],0.99)\n",
    "    #print(mymin,mymax)\n",
    "    Js[-1] = (Js[-1] - mymin)/(mymax - mymin)\n",
    "    # after scaling I'm going to zero out the low signals (new feb 2 2023)\n",
    "    Js[-1][Js[-1]<0.0] = 0.0\n",
    "    # also I think the weights are not strong enough\n",
    "    Ws[-1][Ws[-1]<0.999] = 0.0\n",
    "    \n",
    "    dJs.append([x[1]-x[0] for x in xJs[-1]])\n",
    "    DJs.append(np.prod(dJs[-1]) )\n",
    "    \n",
    "    # note, sometimes xJs don't match Js\n",
    "    s = -1\n",
    "    if len(xJs[-1][s]) != Js[-1].shape[s]:\n",
    "        print('mismatch')\n",
    "        print(f'x size {len(xJs[-1][s])} doesn\\'t match J size {Js[-1].shape[s]}')\n",
    "        n = Js[-1].shape[s] - len(xJs[-1][s]) \n",
    "        d = xJs[-1][s][1] - xJs[-1][s][0]\n",
    "        xJs[-1][s] = np.concatenate((xJs[-1][s],[xJs[-1][s][-1]+d ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'TME07-1' in brain:\n",
    "    image_high_keys = [n.split('_')[-4] for n in image_high_files]\n",
    "elif 'MQC' in brain or 'KO' in brain_path:\n",
    "    image_high_keys = [n.split('_')[-9] for n in image_high_files]\n",
    "else:\n",
    "    image_high_keys = [n.split('_')[-6] for n in image_high_files]\n",
    "image_high_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we get all the neurons\n",
    "neuron_files = []\n",
    "for dirpath, dirnames, filenames in walk(neuron_dir):\n",
    "    # print(f'{dirpath}, {dirnames}, {filenames}')\n",
    "    for filename in filenames:\n",
    "        if '.swc' in filename:\n",
    "            neuron_files.append(join(dirpath,filename))\n",
    "\n",
    "\n",
    "# image_high_ind = 0\n",
    "image_high_ind = 1\n",
    "image_high_file = image_high_files[image_high_ind]\n",
    "image_high_key = image_high_keys[image_high_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the image    \n",
    "Vall = []\n",
    "Eall = []\n",
    "data = np.load(image_high_file,allow_pickle=True)\n",
    "J = data['I']\n",
    "\n",
    "# We decided to ignore voxel positions and use zero-mean convention b/c it is more numerically stable\n",
    "xJ = [d - np.mean(d) for d in data['xI']]\n",
    "\n",
    "key = 'W' if 'W' in data else 'w'\n",
    "WJ = data[key]\n",
    "xJ0 = [xi - xi[0] for xi in xJ]\n",
    "dJ = [xi[1] - xi[0] for xi in xJ]\n",
    "#vminJ = np.quantile(J[WJ>0.9],0.001)\n",
    "if channel == 1 and '04A' in image_high_file and False:\n",
    "    J[J<1.5] = np.min(J[J>=1.5])\n",
    "    J -= np.min(J)\n",
    "    J /= np.max(J)\n",
    "else:\n",
    "    vminJ = np.quantile(J[WJ>0.9],0.1)\n",
    "    vmaxJ = np.quantile(J[WJ>0.9],0.999)\n",
    "\n",
    "# for 0 we need to do 2,1\n",
    "# for 1 we need to do 2,0\n",
    "# for 2 we need to do 1,0\n",
    "extenthigh0 = (xJ[-1][0]-dI[-1],xJ[-1][-1]+dI[-1],xJ[-2][-1]+dI[-2],xJ[-2][0]-dI[-2])\n",
    "extenthigh1 = (xJ[2][0]-dI[2],xJ[2][-1]+dI[2],xJ[0][-1]+dI[0],xJ[0][0]-dI[0])\n",
    "extenthigh2 = (xJ[1][0]-dI[1],xJ[1][-1]+dI[1],xJ[0][-1]+dI[0],xJ[0][0]-dI[0])\n",
    "\n",
    "J0 = np.max(J,0)\n",
    "J1 = np.max(J,1)\n",
    "J2 = np.max(J,2)\n",
    "fig0,ax0 = plt.subplots()\n",
    "ax0.imshow(J0,extent=extenthigh0,vmin=vminJ,vmax=vmaxJ)\n",
    "ax0.set_title(splitext(split(image_high_file)[-1])[0])\n",
    "fig0.canvas.draw()\n",
    "\n",
    "fig1,ax1 = plt.subplots()\n",
    "ax1.imshow(J1,extent=extenthigh1,vmin=vminJ,vmax=vmaxJ)\n",
    "ax1.set_title(splitext(split(image_high_file)[-1])[0])\n",
    "fig1.canvas.draw()\n",
    "\n",
    "fig2,ax2 = plt.subplots()\n",
    "ax2.imshow(J2,extent=extenthigh2,vmin=vminJ,vmax=vmaxJ)\n",
    "ax2.set_title(splitext(split(image_high_file)[-1])[0])\n",
    "fig2.canvas.draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (Solved) Problem 1: files_filter is empty after running cell => empty V => empty phiiVall => ValueError several cells down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "files_filter = list(filter(lambda x: image_high_key in x, neuron_files))\n",
    "# now we load them\n",
    "V = []\n",
    "E = []\n",
    "dJ0 = np.array([0.2,0.2,1.0])\n",
    "for file in files_filter:\n",
    "    \n",
    "    # .swc files for TME12-1 contain a comment on line 1\n",
    "    if brain in ['TME12-1'] or 'MQC' in brain or 'KO' in brain_path:\n",
    "        v_,e_,r_ = load_swc(file, skip=1)\n",
    "    else:\n",
    "        v_,e_,r_ = load_swc(file)\n",
    "    \n",
    "    #v_ = v_ - v_[0] # maybe this? this seems to give good results ( I did this one with old swc)\n",
    "    ##v_ = v_[0] - v_ # maybe this? (I didn't do this one)\n",
    "    \n",
    "    # I think I need to scale by voxel size\n",
    "    v_ *= dJ0  \n",
    "        \n",
    "    #xyzoff = (np.array([int(x[1:]) for x in splitext(split(file)[-1])[0].split('_')[-3:]]))*dJ0\n",
    "    xyzoff = 0.0 # I think no offset here anymore, not sure\n",
    "    \n",
    "    \n",
    "    \n",
    "    v_ += xyzoff\n",
    "    # also account for the coordinate offset\n",
    "    # a zero should correspond to an x[0]\n",
    "    v_ += np.array([xJ[2][0],xJ[1][0],xJ[0][0]])\n",
    "    V.append(v_)\n",
    "    E.append(e_)\n",
    "\n",
    "\n",
    "for i in range(len(V)):\n",
    "    v_ = V[i]\n",
    "    e_ = E[i]\n",
    "    #colors=v_[e_][:,0,0]\n",
    "    #colors = cmap((colors-xI0[0][0])/(xI0[0][-1]-xI0[0][0]))\n",
    "    colors = np.ones(e_.shape[0])[...,None]*np.random.rand(4)\n",
    "    colors[:,-1] = 0.5\n",
    "    lines0 = LineCollection(v_[e_][...,[0,1]],colors=colors)\n",
    "    lines1 = LineCollection(v_[e_][...,[0,2]],colors=colors)\n",
    "    lines2 = LineCollection(v_[e_][...,[1,2]],colors=colors)\n",
    "\n",
    "    ax0.add_collection(lines0)\n",
    "    ax1.add_collection(lines1)\n",
    "    ax2.add_collection(lines2)\n",
    "    \n",
    "Vall.append(V)\n",
    "Eall.append(E)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in the cell below, I have XI as my transform and the inverse\n",
    "# maybe this is leading to interpolation problems\n",
    "the neurons are defined with respect to xJ, the high res images\n",
    "we should therefore define the transform on this domain"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "reg_data['out']: A 0d-array\n",
    "\n",
    "reg_data['out'].item(): A dict containing the following:\n",
    "- A:\n",
    "- v:\n",
    "- xv:\n",
    "- WM:\n",
    "- WA:\n",
    "- WB:\n",
    "- W0:\n",
    "- muB:\n",
    "- muA:\n",
    "- sigmaAB:\n",
    "- sigmaA:\n",
    "- sigmaM:\n",
    "- coeffs:\n",
    "- figA:\n",
    "- figE: (1x3) Energy, Matching, and Reg\n",
    "- figI: (AphiI,3x5) The transformed 10x image for the corresponding slab\n",
    "- figfI: (fAphiI,3x5) ???\n",
    "- figErr: (3x5) Error between original 30x and transformed 10x image\n",
    "- figJ: (3x5) The 30x image for the correspodning slab\n",
    "- figW: (3x5) ???\n",
    "- figV: (3x5) Velocity fields for every 2d slice within the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE, this cell just does one example slice.  it is useful for testing or debugging.  below we will do all slices\n",
    "\n",
    "# Allows notebook to run w/o error since we are missing the 01A transformation file for TME07-1_01A\n",
    "if image_high_key == '01A' and brain == 'TME07-1':\n",
    "    image_high_key = '01B'\n",
    "\n",
    "# now transform the volume into the low res image\n",
    "# we'll accumulate a weight and the image\n",
    "# to do this we have to load the transformations\n",
    "fig_together = plt.figure()\n",
    "JtoI = np.zeros_like(I)\n",
    "WJtoI = np.zeros_like(WI)\n",
    "phiiVall = []\n",
    "\n",
    "# Load dict containing 10x-to-30x registration for 'image_high_key' AND print out 8 figures\n",
    "###### reg_file = glob(join(reg_dir, '*' + image_high_key + '*' + '_ch_' + str(channel_10_to_30) + '*.npz'))[0]\n",
    "reg_file = glob(join(reg_dir, '*' + image_high_key + '*' + '*.npz'))[0]\n",
    "reg_data = np.load(reg_file,allow_pickle=True)\n",
    "# use a fallback for loading with version incompatibility\n",
    "try:\n",
    "    out = reg_data['out'].item()\n",
    "except:\n",
    "    out = backup_unpickle(reg_file)\n",
    "    \n",
    "tform = emlddmm.compose_sequence([emlddmm.Transform(out['v'],domain=out['xv']),emlddmm.Transform(out['A'])],XI)\n",
    "phiiJ = emlddmm.apply_transform_float(xJ,J[None],tform,padding_mode='zeros').numpy()\n",
    "phiiW = emlddmm.apply_transform_float(xJ,WJ[None],tform,padding_mode='zeros').numpy()    \n",
    "JtoI += (phiiJ[0] - vminJ)/(vmaxJ-vminJ)*phiiW[0] #not sure if I should do this for normalization    \n",
    "WJtoI += phiiW[0]\n",
    "toshow = ((JtoI)/(WJtoI))[None]\n",
    "##### toshow /= np.max(JtoI)\n",
    "\n",
    "# Overlays 30x image on transformed 10x image\n",
    "emlddmm.draw(np.stack((toshow[0],(I-vminI)/(vmaxI-vminI),toshow[0])),xI,vmin=0,vmax=1,fig=fig_together)\n",
    "fig_together.canvas.draw()\n",
    "\n",
    "# now we have to map the neurons in, and draw them\n",
    "# adding XJ this is a change\n",
    "XJ = np.stack(np.meshgrid(*xJ,indexing='ij'))\n",
    "tform = emlddmm.compose_sequence([emlddmm.Transform(out['A'],direction='b'),emlddmm.Transform(out['v'],direction='b',domain=out['xv'])],XJ)\n",
    "#tform = emlddmm.compose_sequence([emlddmm.Transform(out['A'],direction='b'),emlddmm.Transform(out['v'],direction='b',domain=out['xv'])],XI)\n",
    "phiiV = []\n",
    "for vi in V:\n",
    "    # note swap xyz to zyx and back\n",
    "    phiiV.append( emlddmm.interp(xJ,tform,vi.T[::-1,:,None,None].astype(np.float32))[...,0,0].T.numpy()[...,::-1] )\n",
    "    #phiiV.append( emlddmm.interp(xI,tform,vi.T[::-1,:,None,None].astype(np.float32))[...,0,0].T.numpy()[...,::-1] )\n",
    "phiiVall.append(phiiV)\n",
    "\n",
    "\n",
    "\n",
    "# Displays 30x MIP above empty background of the same size as the 10x image (create a max projection, accounting for nans)\n",
    "fig,ax = plt.subplots()\n",
    "toshowmax = np.array(toshow[0,0])\n",
    "nanind = np.isnan(toshowmax)\n",
    "ax.imshow(toshowmax,vmin=0,vmax=1,extent=extentlow0)\n",
    "fig.canvas.draw()\n",
    "for i in range(1,toshow.shape[1]):\n",
    "    toshownew = np.array(toshow[0,i])\n",
    "    # we update toshowmax if there are two things    \n",
    "    # if they are both nan, set to nan    \n",
    "    # if the old one is nan and the new one is not, set to the new one\n",
    "    # if the old one is not nan and the new one is, set to the new one\n",
    "    # if both are not nan, set to the max\n",
    "    # recall, any inequality involving nan gives false\n",
    "    nanindnew = np.isnan(toshownew)\n",
    "    inds = np.logical_or( toshownew > toshowmax , np.logical_not(nanindnew)*nanind  )\n",
    "    toshowmax[inds] = toshownew[inds]\n",
    "\n",
    "    nanind = np.isnan(toshowmax)\n",
    "\n",
    "ax.cla()\n",
    "ax.imshow(toshowmax,vmin=0,vmax=1,extent=extentlow0)\n",
    "#plt.pause(0.1)\n",
    "fig.canvas.draw()\n",
    "\n",
    "\n",
    "# Displays 30x MIP + neurons above empty background of the same size as the 10x image (show them with neurons)\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(toshowmax,vmin=0,vmax=1,extent=extentlow0)\n",
    "for j in range(len(phiiVall)):\n",
    "    for i in range(len(phiiVall[j])):\n",
    "        v_ = phiiVall[j][i]\n",
    "        e_ = Eall[j][i]\n",
    "        #colors=v_[e_][:,0,0]\n",
    "        #colors = cmap((colors-xI0[0][0])/(xI0[0][-1]-xI0[0][0]))\n",
    "        colors = np.ones(e_.shape[0])[...,None]*np.random.rand(4)\n",
    "        colors[:,-1] = 0.5\n",
    "        lines0 = LineCollection(v_[e_][...,[0,1]],colors=colors,linewidths=0.5)\n",
    "        #lines1 = LineCollection(v_[e_][...,[0,2]],colors=colors,linewidths=0.5)\n",
    "        #lines2 = LineCollection(v_[e_][...,[1,2]],colors=colors,linewidths=0.5)\n",
    "\n",
    "        ax.add_collection(lines0)\n",
    "        #ax1.add_collection(lines1)\n",
    "        #ax2.add_collection(lines2)\n",
    "\n",
    "# Displays 30x MIP + neurons + 10x MIP (show again with images)\n",
    "Ishow = (np.max(I,0) - vminI)/(vmaxI-vminI)\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(Ishow[...,None]**0.5*np.array([[[1.0,0.0,0.0]]]),vmin=0,vmax=1,extent=extentlow0)\n",
    "ax.imshow(toshowmax[...,None]**0.5*np.array([[[0.0,1.0,0.0]]]),vmin=0,vmax=1,alpha=0.4,cmap='Greens',extent=extentlow0)\n",
    "\n",
    "for j in range(len(phiiVall)):\n",
    "    for i in range(len(phiiVall[j])):\n",
    "        v_ = phiiVall[j][i]\n",
    "        e_ = Eall[j][i]\n",
    "        #colors=v_[e_][:,0,0]\n",
    "        #colors = cmap((colors-xI0[0][0])/(xI0[0][-1]-xI0[0][0]))\n",
    "        colors = np.ones(e_.shape[0])[...,None]*np.random.rand(4)\n",
    "        colors[:,-1] = 0.5\n",
    "        lines0 = LineCollection(v_[e_][...,[0,1]],colors=colors,linewidths=0.5)\n",
    "        #lines1 = LineCollection(v_[e_][...,[0,2]],colors=colors)\n",
    "        #lines2 = LineCollection(v_[e_][...,[1,2]],colors=colors)\n",
    "\n",
    "        ax.add_collection(lines0)\n",
    "        #ax1.add_collection(lines1)\n",
    "        #ax2.add_collection(lines2)\n",
    "ax.set_title(f'{splitext(basename(image_low_file))[0]}')\n",
    "\n",
    "\n",
    "\n",
    "# in addition, we want to map the atlas onto this slice\n",
    "tform_low_to_at = emlddmm.compose_sequence([\n",
    "        emlddmm.Transform(dataat['v'].transpose(0,-1,1,2,3),domain=dataat['xv'],direction='b'),\n",
    "        emlddmm.Transform(dataat['A'],direction='b'),\n",
    "        emlddmm.Transform(dataat['TJ'][low_ind],direction='b'),\n",
    "        emlddmm.Transform(dataat['vJ'][low_ind].transpose(0,-1,1,2,3),domain=dataat['xvJ'][low_ind],direction='b'),\n",
    "        emlddmm.Transform(dataat['AJ'][low_ind],direction='b')\n",
    "    ][::-1],XI)\n",
    "\n",
    "# get segmentation labels\n",
    "from scipy.interpolate import interpn\n",
    "Stformed = interpn(xS,S[0],tform_low_to_at.permute(1,2,3,0),bounds_error=False,fill_value=0,method='nearest')\n",
    "\n",
    "\n",
    "# mode projection is like a max projection here\n",
    "from scipy.stats import mode\n",
    "m,c = mode(Stformed,axis=0,)\n",
    "m = m[0]\n",
    "\n",
    "\n",
    "\n",
    "# from m we'll get boundaries\n",
    "mb = 1 - (m == np.roll(m,shift=1,axis=0))*(m == np.roll(m,shift=1,axis=1))*(m == np.roll(m,shift=-1,axis=0))*(m == np.roll(m,shift=-1,axis=1))\n",
    "mb = mb*1.0\n",
    "# and add it to the image\n",
    "ax.imshow(np.stack((mb,mb,mb,mb*0.125),-1),interpolation='none',extent=extentlow0,cmap='gray')\n",
    "\n",
    "# now cp\n",
    "mcp = np.zeros_like(m)\n",
    "for id_ in cp_ids:\n",
    "    mcp = np.logical_or(mcp,m==id_)\n",
    "mcpb = 1 - (mcp == np.roll(mcp,shift=1,axis=0))*(mcp == np.roll(mcp,shift=1,axis=1))*(mcp == np.roll(mcp,shift=-1,axis=0))*(mcp == np.roll(mcp,shift=-1,axis=1))\n",
    "mcpb = mcpb*1.0\n",
    "ax.imshow(np.stack((mcpb*0,mcpb*0,mcpb,mcpb*0.5),-1),interpolation='none',extent=extentlow0,cmap='gray')\n",
    "# note, if you want a fillin, use mcp instead of mcpb\n",
    "\n",
    "# TODO replace this output location with something we can specify\n",
    "# actually this does not need to be uncommented, the figure should get saved below\n",
    "#plt.savefig(f'/home/abenneck/dragonfly_work/dragonfly_outputs/{brain}/step3QC/10x_30x_neuron_{image_high_key}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.imshow(np.stack((mb,mb,mb,mb),-1)*1.0,interpolation='none',extent=extentlow0,cmap='gray',alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check in 3D\n",
    "vsave = []\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.view_init(0,0)\n",
    "for j in range(len(phiiVall)):\n",
    "    for i in range(len(phiiVall[j])):\n",
    "        v_ = phiiVall[j][i]\n",
    "        #v_ = Vall[j][i]\n",
    "        e_ = Eall[j][i]\n",
    "        #colors=v_[e_][:,0,0]\n",
    "        #colors = cmap((colors-xI0[0][0])/(xI0[0][-1]-xI0[0][0]))\n",
    "        colors = np.ones(e_.shape[0])[...,None]*np.random.rand(4)\n",
    "        colors[:,-1] = 0.5\n",
    "        lines0 = Line3DCollection(v_[e_],colors=colors,linewidths=0.5)\n",
    "        #lines1 = LineCollection(v_[e_][...,[0,2]],colors=colors)\n",
    "        #lines2 = LineCollection(v_[e_][...,[1,2]],colors=colors)\n",
    "\n",
    "        ax.add_collection(lines0)\n",
    "        #ax1.add_collection(lines1)\n",
    "        #ax2.add_collection(lines2)\n",
    "        # we don't want nans!\n",
    "        if np.any(np.isnan(v_)): continue\n",
    "        vsave.append(v_)\n",
    "        \n",
    "datasave_ = np.concatenate(vsave)\n",
    "vmin = np.min(datasave_,0)\n",
    "vmax = np.max(datasave_,0)\n",
    "r = vmax-vmin\n",
    "rmax = np.max(r)\n",
    "c = (vmin+vmax)/2\n",
    "vmin = c-rmax/2\n",
    "vmax = c+rmax/2\n",
    "ax.set_xlim(vmin[0],vmax[0])\n",
    "ax.set_ylim(vmin[1],vmax[1])\n",
    "ax.set_zlim(vmin[2],vmax[2])        \n",
    "\n",
    "\n",
    "\n",
    "# check in 3D\n",
    "vsave = []\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.view_init(0,0)\n",
    "for j in range(len(phiiVall)):\n",
    "    for i in range(len(phiiVall[j])):\n",
    "        v_ = phiiVall[j][i]\n",
    "        v_ = Vall[j][i]\n",
    "        e_ = Eall[j][i]\n",
    "        #colors=v_[e_][:,0,0]\n",
    "        #colors = cmap((colors-xI0[0][0])/(xI0[0][-1]-xI0[0][0]))\n",
    "        colors = np.ones(e_.shape[0])[...,None]*np.random.rand(4)\n",
    "        colors[:,-1] = 0.5\n",
    "        lines0 = Line3DCollection(v_[e_],colors=colors,linewidths=0.5)\n",
    "        #lines1 = LineCollection(v_[e_][...,[0,2]],colors=colors)\n",
    "        #lines2 = LineCollection(v_[e_][...,[1,2]],colors=colors)\n",
    "\n",
    "        ax.add_collection(lines0)\n",
    "        #ax1.add_collection(lines1)\n",
    "        #ax2.add_collection(lines2)\n",
    "        if np.any(np.isnan(v_)): continue\n",
    "        vsave.append(v_)\n",
    "        \n",
    "datasave_ = np.concatenate(vsave)\n",
    "vmin = np.min(datasave_,0)\n",
    "vmax = np.max(datasave_,0)\n",
    "r = vmax-vmin\n",
    "rmax = np.max(r)\n",
    "c = (vmin+vmax)/2\n",
    "vmin = c-rmax/2\n",
    "vmax = c+rmax/2\n",
    "ax.set_xlim(vmin[0],vmax[0])\n",
    "ax.set_ylim(vmin[1],vmax[1])\n",
    "ax.set_zlim(vmin[2],vmax[2])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it looks like some of them got completely flat\n",
    "# maybe this is due to boundary conditions on the diffeomorphism?\n",
    "# still under investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('stop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the loop below will collect and process data for all slabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: ValueError (See output below cell)\n",
    "*May resolve itself after solving Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize variables to save\n",
    "# I need\n",
    "# my low res slab image which will be incremented\n",
    "# my high res slab image\n",
    "# my neurons\n",
    "# my neuron labels\n",
    "\n",
    "# these variables will store all slabs\n",
    "neurons_orig = []\n",
    "neurons_one_step = []\n",
    "neurons = []\n",
    "neuron_labels = []\n",
    "neuron_edges = []\n",
    "neuron_labels_noise = []\n",
    "images = np.zeros((3,Iat.shape[1],Iat.shape[2],Iat.shape[3]))\n",
    "set_v_to_zero = False\n",
    "files_all = [] \n",
    "# we get all the files at once based on this output format\n",
    "# now we get all the neurons, this is the same each time\n",
    "files_ = []\n",
    "for dirpath, dirnames, filenames in walk(neuron_dir):\n",
    "    for filename in filenames:\n",
    "        if 'TME07-1' in brain and ('01A' in filename or '01B' in filename):\n",
    "            continue\n",
    "        if '.swc' in filename:\n",
    "            files_.append(join(dirpath,filename))\n",
    "\n",
    "# NOTE\n",
    "# in certain cases, we could not map some of the blocks, if there were problems with the tissue\n",
    "# in one cases, I added a '-1' added to prevent looping through slice 9 (Missing images)\n",
    "# however, we need a more general way of doing this, because different cases may have different missing\n",
    "# or poor quality slabs\n",
    "# in some cases, there was a high resolution image missing\n",
    "# but only in very few cases was there a low resolution missing\n",
    "# we think it's only for TME 07\n",
    "# we need to do two things to fix this\n",
    "# first, loop over all the files for low ind below (don't subtract 1)\n",
    "# second, when loading transforms, we should index them by \"low_ind\" and not \"low_ind-1\" \n",
    "# (this shows up in 2 places, at_to_low, and low_to_at)\n",
    "# BUT, in special cases, like TME07, we will need to fix this\n",
    "# TODO: we need to check what happens if we're missing a high res file\n",
    "# NOTE: for tme08, we might be missing a high res image\n",
    "for low_ind in range(0,len(image_low_files)): \n",
    "\n",
    "    # Skip first slice of TME07-1 due to missing data\n",
    "    if 'TME07-1' in brain and low_ind == 0:\n",
    "        continue\n",
    "    \n",
    "    # load the low res image\n",
    "    image_low_file = image_low_files[low_ind]\n",
    "    if 'TME07-1' in brain:\n",
    "        image_low_key = image_low_file.split('_')[-4] # TODO check this if output format changes\n",
    "    elif 'MQC' in brain or 'KO' in brain_path:\n",
    "        image_low_key = image_low_file.split('_')[-9]\n",
    "    else:\n",
    "        image_low_key = image_low_file.split('_')[-6] # TODO check this if output format changes\n",
    "    data = np.load(image_low_file,allow_pickle=True)\n",
    "    I = data['I']\n",
    "\n",
    "    # We decided to ignore voxel positions and use zero-mean convention b/c it is more numerically stable\n",
    "    xI = [d - np.mean(d) for d in data['xI']]\n",
    "    \n",
    "    # check the size\n",
    "    if len(xI[-1]) != I.shape[-1]:        \n",
    "        xI[-1] = np.concatenate((xI[-1],xI[-1][-1][None] + (xI[-1][1]-xI[-1][0])))\n",
    "    \n",
    "    XI = np.stack(np.meshgrid(*xI,indexing='ij'))\n",
    "    key = 'W' if 'W' in data else 'w'\n",
    "    WI = data[key]\n",
    "    dI = [xi[1] - xi[0] for xi in xI]\n",
    "    \n",
    "    # get extent and draw it\n",
    "    extentlow0 = (xI[2][0]-dI[2],xI[2][-1]+dI[2],xI[1][-1]+dI[1],xI[1][0]-dI[1])\n",
    "    extentlow1 = (xI[2][0]-dI[2],xI[2][-1]+dI[2],xI[0][-1]+dI[0],xI[0][0]-dI[0])\n",
    "    extentlow2 = (xI[1][0]-dI[1],xI[1][-1]+dI[1],xI[0][-1]+dI[0],xI[0][0]-dI[0])\n",
    "    \n",
    "    \n",
    "    I0 = np.max(I,0)\n",
    "    I1 = np.max(I,1)\n",
    "    I2 = np.max(I,2)\n",
    "    fig,ax = plt.subplots()\n",
    "    # vminI = np.min(I[WI>0.9])\n",
    "    vminI = np.quantile(I.ravel(),0.4) # Made change on 6/27/23 in order to make each slice output figure show the 10x, 30x, AND neuron\n",
    "    vmaxI = np.max(I[WI>0.9])\n",
    "    ax.imshow(I0,extent=extentlow0,vmin=vminI,vmax=vmaxI)\n",
    "    ax.set_title(splitext(split(image_low_file)[-1])[0])\n",
    "    \n",
    "    \n",
    "    # now we find the corresponding high res files\n",
    "    channel_high = channel_10_to_30\n",
    "    image_high_files = []\n",
    "    for dirpath, dirnames, filenames in walk(image_dir):\n",
    "        if 'TME07-1' in brain:\n",
    "            files = glob(join(dirpath,f'*30x*{image_low_key}*channel_{channel_high}*.npz'))\n",
    "        elif 'MQC' in brain:\n",
    "            files = glob(join(dirpath,f'*30X_Str_{image_low_key}*ch_{channel_high}*.npz'))\n",
    "        else:\n",
    "            files = glob(join(dirpath,f'*30x*{image_low_key}*ch_{channel_high}*.npz'))\n",
    "        image_high_files.extend(files)\n",
    "    image_high_files.sort()\n",
    "    image_high_files = list(filter(temp_filter, image_high_files))\n",
    "    \n",
    "\n",
    "    # there should be two\n",
    "    if 'TME07-1' in brain:\n",
    "        image_high_keys = [n.split('_')[-4] for n in image_high_files]\n",
    "    elif 'MQC' in brain or 'KO' in brain_path:\n",
    "        image_high_keys = [n.split('_')[-9] for n in image_high_files]\n",
    "    else:\n",
    "        image_high_keys = [n.split('_')[-6] for n in image_high_files]\n",
    "    \n",
    "    # we'll extract this slice\n",
    "    files = list(filter(lambda x: '_'+image_low_key in x, files_))\n",
    "    files_all.append(files)\n",
    "    \n",
    "                \n",
    "                \n",
    "                \n",
    "    # now we start processing\n",
    "    fig_together = plt.figure()\n",
    "    JtoI = np.zeros_like(I)\n",
    "    WJtoI = np.zeros_like(WI)\n",
    "    \n",
    "    # note these variables with an \"all\" suffix will store left and right\n",
    "    phiiVall = []\n",
    "    Vall = []\n",
    "    Eall = []\n",
    "    Rall = []\n",
    "    neuron_labels_all_QC = []\n",
    "    # now we will need to loop through, the files above\n",
    "    # print(f'ihk early: {image_high_key}')\n",
    "    print(f'all ihk (idx: {low_ind}): {image_high_keys}')\n",
    "    # print(f'all ihk files (idx: {low_ind}): {image_high_files}')\n",
    "    print(f'image_low_key: {image_low_key}')\n",
    "    for image_high_file,image_high_key in zip(image_high_files,image_high_keys):\n",
    "\n",
    "        # load the image    \n",
    "        data = np.load(image_high_file,allow_pickle=True)\n",
    "        J = data['I']\n",
    "\n",
    "        # We decided to ignore voxel positions and use zero-mean convention b/c it is more numerically stable\n",
    "        xJ = [d - np.mean(d) for d in data['xI']]\n",
    "    \n",
    "        key = 'W' if 'W' in data else 'w'\n",
    "        WJ = data[key]\n",
    "        xJ0 = [xi - xi[0] for xi in xJ]\n",
    "        dJ = [xi[1] - xi[0] for xi in xJ]\n",
    "        if channel == 1 and '04A' in image_high_file and False:\n",
    "            J[J<1.5] = np.min(J[J>=1.5])\n",
    "            J -= np.min(J)\n",
    "            J /= np.max(J)\n",
    "        elif channel == 0 and  '04A' in image_high_file  and False:\n",
    "            J[J<1.5] = np.min(J[J>=1.5])\n",
    "            J -= np.min(J)\n",
    "            J /= np.max(J)\n",
    "        elif channel == 0 and '01B' in image_high_file  and False:\n",
    "            J[J<1.5] = np.min(J[J>=1.5])\n",
    "            J -= np.min(J)\n",
    "            J /= np.max(J)\n",
    "        else:\n",
    "            vminJ = np.quantile(J[WJ>0.9],0.1)\n",
    "            vmaxJ = np.quantile(J[WJ>0.9],0.999)\n",
    "    \n",
    "        \n",
    "\n",
    "        extenthigh0 = (xJ[2][0]-dI[2],xJ[2][-1]+dI[2],xJ[1][-1]+dI[1],xJ[1][0]-dI[1])\n",
    "        extenthigh1 = (xJ[2][0]-dI[2],xJ[2][-1]+dI[2],xJ[0][-1]+dI[0],xJ[0][0]-dI[0])\n",
    "        extenthigh2 = (xJ[1][0]-dI[1],xJ[1][-1]+dI[1],xJ[0][-1]+dI[0],xJ[0][0]-dI[0])\n",
    "        J0 = np.max(J,0)\n",
    "        J1 = np.max(J,1)\n",
    "        J2 = np.max(J,2)\n",
    "        fig0,ax0 = plt.subplots()\n",
    "        ax0.imshow(J0,extent=extenthigh0,vmin=vminJ,vmax=vmaxJ)\n",
    "        ax0.set_title(splitext(split(image_high_file)[-1])[0])\n",
    "        fig0.canvas.draw()\n",
    "\n",
    "        fig1,ax1 = plt.subplots()\n",
    "        ax1.imshow(J1,extent=extenthigh1,vmin=vminJ,vmax=vmaxJ)\n",
    "        ax1.set_title(splitext(split(image_high_file)[-1])[0])\n",
    "        fig1.canvas.draw()\n",
    "\n",
    "        fig2,ax2 = plt.subplots()\n",
    "        ax2.imshow(J2,extent=extenthigh2,vmin=vminJ,vmax=vmaxJ)\n",
    "        ax2.set_title(splitext(split(image_high_file)[-1])[0])\n",
    "        fig2.canvas.draw()\n",
    "\n",
    "        # print(f'ihk mid: {image_high_key}')    \n",
    "        files_filter = list(filter(lambda x: image_high_key in x, files))\n",
    "        # now we load them\n",
    "        V = []\n",
    "        E = []\n",
    "        R = []\n",
    "        neuron_labels_QC = []\n",
    "        dJ0 = np.array([0.2,0.2,1.0])\n",
    "        for file in files_filter:\n",
    "            # print(file)\n",
    "\n",
    "            # .swc files for TME12-1 contain a comment on line 1\n",
    "            if brain in ['TME12-1'] or 'MQC' in brain or 'KO' in brain_path:\n",
    "                v_,e_,r_ = load_swc(file, skip=1)\n",
    "            else:\n",
    "                v_,e_,r_ = load_swc(file)\n",
    "                \n",
    "            # v_ = v_ - v_[0] # maybe this? this seems to give good results\n",
    "            # #v_ = v_[0] - v_ # maybe this?\n",
    "            v_ *= dJ0  \n",
    "            # xyzoff = (np.array([int(x[1:]) for x in splitext(split(file)[-1])[0].split('_')[-3:]]))*dJ0\n",
    "            xyzoff = 0.0\n",
    "            v_ += xyzoff\n",
    "            # also account for the coordinate offset\n",
    "            # a zero should correspond to an x[0]\n",
    "            v_ += np.array([xJ[2][0],xJ[1][0],xJ[0][0]])\n",
    "            V.append(v_)\n",
    "            E.append(e_)\n",
    "            R.append(r_)\n",
    "            \n",
    "            # (08/04/23) Appends neuron num (###) to list, so that QC figures can have correct neuron ###\n",
    "            neuron_labels_QC.append((file.split('/')[-1]).split('_')[0])\n",
    "\n",
    "\n",
    "        for i in range(len(V)):\n",
    "            v_ = V[i]\n",
    "            e_ = E[i]\n",
    "            #colors=v_[e_][:,0,0]\n",
    "            #colors = cmap((colors-xI0[0][0])/(xI0[0][-1]-xI0[0][0]))\n",
    "            colors = np.ones(e_.shape[0])[...,None]*np.random.rand(4)\n",
    "            colors[:,-1] = 0.5\n",
    "            lines0 = LineCollection(v_[e_][...,[0,1]],colors=colors)\n",
    "            lines1 = LineCollection(v_[e_][...,[0,2]],colors=colors)\n",
    "            lines2 = LineCollection(v_[e_][...,[1,2]],colors=colors)\n",
    "\n",
    "            ax0.add_collection(lines0)\n",
    "            ax1.add_collection(lines1)\n",
    "            ax2.add_collection(lines2)\n",
    "\n",
    "        Vall.append(V)\n",
    "        Eall.append(E)\n",
    "        Rall.append(R)\n",
    "        neuron_labels_all_QC.append(neuron_labels_QC)\n",
    "\n",
    "        # now transform the volume into the low res image\n",
    "        # we'll accumulate a weight and the image\n",
    "        # to do this we have to load the transformations\n",
    "        # print(f'ihk end: {image_high_key}')    \n",
    "        reg_file = glob(join(reg_dir, '*' + image_high_key + '*.npz'))[0]\n",
    "        # print(reg_file)\n",
    "        #reg_file = glob(join(reg_dir, '*' + image_high_key + '*' + '_ch_' + str(channel_10_to_30) + '*.npz'))[0]\n",
    "        reg_data = np.load(reg_file,allow_pickle=True)\n",
    "        try:\n",
    "            out = reg_data['out'].item()\n",
    "        except:\n",
    "            out = backup_unpickle(reg_file)\n",
    "        \n",
    "        \n",
    "        \n",
    "        tform = emlddmm.compose_sequence([emlddmm.Transform(out['v']*(1-set_v_to_zero),domain=out['xv']),emlddmm.Transform(out['A'])],XI)\n",
    "        phiiJ = emlddmm.apply_transform_float(xJ,J[None],tform,padding_mode='zeros').numpy()\n",
    "        phiiW = emlddmm.apply_transform_float(xJ,WJ[None],tform,padding_mode='zeros').numpy()    \n",
    "        JtoI += (phiiJ[0] - vminJ)/(vmaxJ-vminJ)*phiiW[0] #not sure if I should do this for normalization    \n",
    "        WJtoI += phiiW[0]\n",
    "        toshow = ((JtoI)/(WJtoI))[None]\n",
    "        #toshow /= np.max(JtoI)\n",
    "        # I'd like to blend it now\n",
    "        emlddmm.draw(np.stack((toshow[0],(I-vminI)/(vmaxI-vminI),toshow[0])),xI,vmin=0,vmax=1,fig=fig_together)\n",
    "        fig_together.canvas.draw()\n",
    "\n",
    "        # now we have to map the neurons in, and draw them\n",
    "        XJ = np.stack(np.meshgrid(*xJ,indexing='ij'))\n",
    "        #tform = emlddmm.compose_sequence([emlddmm.Transform(out['A'],direction='b'),emlddmm.Transform(out['v']*(1-set_v_to_zero),direction='b',domain=out['xv'])],XI)\n",
    "        tform = emlddmm.compose_sequence([emlddmm.Transform(out['A'],direction='b'),emlddmm.Transform(out['v']*(1-set_v_to_zero),direction='b',domain=out['xv'])],XJ)\n",
    "        phiiV = []\n",
    "        for vi in V:\n",
    "            # note swap xyz to zyx and back\n",
    "            #phiiV.append( emlddmm.interp(xI,tform,vi.T[::-1,:,None,None].astype(np.float32))[...,0,0].T.numpy()[...,::-1] )\n",
    "            phiiV.append( emlddmm.interp(xJ,tform,vi.T[::-1,:,None,None].astype(np.float32))[...,0,0].T.numpy()[...,::-1] )\n",
    "        phiiVall.append(phiiV) # here we add left side and right side\n",
    "        \n",
    "        \n",
    "    # now we are out of the left right high res loop    \n",
    "    # create a max projection, accounting for nans\n",
    "    \n",
    "    #fig,ax = plt.subplots()\n",
    "    toshowmax = np.array(toshow[0,0])\n",
    "    nanind = np.isnan(toshowmax)\n",
    "    #ax.imshow(toshowmax,vmin=0,vmax=1,extent=extentlow0)\n",
    "    #fig.canvas.draw()\n",
    "    for i in range(1,toshow.shape[1]):\n",
    "        toshownew = np.array(toshow[0,i])\n",
    "        # we update toshowmax if there are two things    \n",
    "        # if they are both nan, set to nan    \n",
    "        # if the old one is nan and the new one is not, set to the new one\n",
    "        # if the old one is not nan and the new one is, set to the new one\n",
    "        # if both are not nan, set to the max\n",
    "        # recall, any inequality involving nan gives false\n",
    "        nanindnew = np.isnan(toshownew)\n",
    "        inds = np.logical_or( toshownew > toshowmax , np.logical_not(nanindnew)*nanind  )\n",
    "        toshowmax[inds] = toshownew[inds]\n",
    "\n",
    "        nanind = np.isnan(toshowmax)\n",
    "\n",
    "        #ax.cla()\n",
    "        #ax.imshow(toshowmax,vmin=0,vmax=1,extent=extentlow0)\n",
    "        #plt.pause(0.1)\n",
    "        #fig.canvas.draw()\n",
    "        \n",
    "        \n",
    "    # show them with neurons\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.imshow(toshowmax,vmin=0,vmax=1,extent=extentlow0)\n",
    "    for j in range(len(phiiVall)):\n",
    "        for i in range(len(phiiVall[j])):\n",
    "            v_ = phiiVall[j][i]\n",
    "            e_ = Eall[j][i]\n",
    "            #colors=v_[e_][:,0,0]\n",
    "            #colors = cmap((colors-xI0[0][0])/(xI0[0][-1]-xI0[0][0]))\n",
    "            colors = np.ones(e_.shape[0])[...,None]*np.random.rand(4)\n",
    "            colors[:,-1] = 0.5\n",
    "            lines0 = LineCollection(v_[e_][...,[0,1]],colors=colors,linewidths=0.5)\n",
    "            #lines1 = LineCollection(v_[e_][...,[0,2]],colors=colors,linewidths=0.5)\n",
    "            #lines2 = LineCollection(v_[e_][...,[1,2]],colors=colors,linewidths=0.5)\n",
    "\n",
    "            ax.add_collection(lines0)\n",
    "            #ax1.add_collection(lines1)\n",
    "            #ax2.add_collection(lines2)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # ===============================\n",
    "    # ===== GENERATE QC FIGURES =====\n",
    "    # ===============================\n",
    "    \n",
    "    # === Generate 10x (red) img of slice ===\n",
    "    Ishow = (np.max(I,0) - vminI)/(vmaxI-vminI)\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.imshow(Ishow[...,None]**0.5*np.array([[[1.0,0.0,0.0]]]),vmin=0,vmax=1,extent=extentlow0)\n",
    "    \n",
    "    # (7/24/23) Nick asked that the images ONLY have the red map (and not the green)\n",
    "    # ax.imshow(toshowmax[...,None]**0.5*np.array([[[0.0,1.0,0.0]]]),vmin=0,vmax=1,alpha=0.4,cmap='Greens',extent=extentlow0)\n",
    "    \n",
    "    ax.set_title(f'{splitext(basename(image_low_file))[0][:-5]}_blank')    \n",
    "    fig.savefig(join(output_dir,f'{splitext(basename(image_low_file))[0][:-5]}_blank.jpg'), dpi = 500.0)\n",
    "\n",
    "    # === Generate individual neuron jpegs (blue) and map of ALL neurons (multicolor) ===\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.imshow(np.zeros(np.shape(Ishow[...,None])), extent = extentlow0, cmap = 'inferno')\n",
    "\n",
    "    # (7/24/23) idx defined at beginning of cell, so that it continually increments across entire brain\n",
    "    for j in range(len(phiiVall)):\n",
    "        for i in range(len(phiiVall[j])):\n",
    "            v_ = phiiVall[j][i]\n",
    "            e_ = Eall[j][i]\n",
    "            neuron_num = neuron_labels_all_QC[j][i]\n",
    "            \n",
    "            # # For multi-colored neurons\n",
    "            colors = np.ones(e_.shape[0])[...,None]*np.random.rand(4)\n",
    "            colors[:,-1] = 0.5\n",
    "            lines0 = LineCollection(v_[e_][...,[0,1]],colors=colors,linewidths=0.5)\n",
    "            ax.add_collection(lines0)\n",
    "\n",
    "            # For [0,0,1] (Blue-only) neurons\n",
    "            colors = np.zeros(e_.shape[0])[...,None]*np.ones(4)\n",
    "            colors[:,-1] = 0.5\n",
    "            colors[:,-2] = 1.0\n",
    "\n",
    "            # (07/18/23) Save each neuron as an individual jpeg\n",
    "            lines0_ = LineCollection(v_[e_][...,[0,1]],colors=colors,linewidths=0.5)\n",
    "            fig_, ax_ = plt.subplots()\n",
    "            ax_.imshow(np.zeros(np.shape(Ishow[...,None])), extent = extentlow0, cmap = 'inferno')\n",
    "            ax_.add_collection(lines0_)\n",
    "            ax_.set_title(f'{neuron_num}_{splitext(basename(image_low_file))[0][:-5]}')\n",
    "            \n",
    "            fig_.savefig(join(output_dir,f'{splitext(basename(image_low_file))[0][:-5]}_{neuron_num}.jpg'), dpi = 500.0)            \n",
    "                      \n",
    "    ax.set_title(f'{splitext(basename(image_low_file))[0][:-5]}_neuron')\n",
    "\n",
    "    # (07/18/23) Updated dpi to 500\n",
    "    fig.savefig(join(output_dir,f'{splitext(basename(image_low_file))[0][:-5]}_neuron.jpg'), dpi = 500.0)\n",
    "            \n",
    "            \n",
    "    # okay now we need to map just one slice\n",
    "    # I'll just use my low res slab, and not worry about high res until later\n",
    "    # so, first for the images\n",
    "    # we start with XIat, we map it forward\n",
    "    # we will need to do some permuting\n",
    "    \n",
    "    tform_at_to_low = emlddmm.compose_sequence([\n",
    "        emlddmm.Transform(dataat['v'].transpose(0,-1,1,2,3)*(1-set_v_to_zero),domain=dataat['xv']),\n",
    "        emlddmm.Transform(dataat['A']),\n",
    "        emlddmm.Transform(dataat['TJ'][low_ind]),\n",
    "        emlddmm.Transform(dataat['vJ'][low_ind].transpose(0,-1,1,2,3)*(1-set_v_to_zero),domain=dataat['xvJ'][low_ind]),\n",
    "        emlddmm.Transform(dataat['AJ'][low_ind])\n",
    "    ],XIat)\n",
    "\n",
    "\n",
    "\n",
    "    Ishow_ = (I - vminI)/(vmaxI-vminI)\n",
    "    toshow_ = np.array(toshow)\n",
    "    toshow_[np.isnan(toshow_)] = 0.0\n",
    "\n",
    "    print(f'toshow.shape: {toshow.shape}')\n",
    "    print(f'Ishow_.shape: {Ishow_.shape}')\n",
    "    \n",
    "    outtest = emlddmm.apply_transform_float(xI,np.concatenate((toshow_,Ishow_[None])),tform_at_to_low,padding_mode='zeros') \n",
    "    \n",
    "    \n",
    "    Iatshow = np.array(Iat[0][None])\n",
    "    vlim = np.quantile(Iatshow,[0.001,0.999])\n",
    "    Iatshow -= vlim[0]\n",
    "    Iatshow /= vlim[1]-vlim[0]\n",
    "    emlddmm.draw(np.concatenate((outtest**0.5,Iatshow*0.5)),xIat,vmin=0,vmax=1,n_slices=8)\n",
    "\n",
    "    # save this\n",
    "    images += np.concatenate((outtest**0.5,Iatshow*0.5))\n",
    "    \n",
    "    # okay now we need to map just one slice\n",
    "    # I'll just use my low res slab, and not worry about high res until later\n",
    "    # so, first for the images\n",
    "    # we start with XIat, we map it forward\n",
    "    # we will need to do some permuting\n",
    "    \n",
    "    # did I do this in the right order? yes note that I reversed the order later\n",
    "    tform_low_to_at = emlddmm.compose_sequence([\n",
    "        emlddmm.Transform(dataat['v'].transpose(0,-1,1,2,3)*(1-set_v_to_zero),domain=dataat['xv'],direction='b'),\n",
    "        emlddmm.Transform(dataat['A'],direction='b'),\n",
    "        emlddmm.Transform(dataat['TJ'][low_ind],direction='b'),\n",
    "        emlddmm.Transform(dataat['vJ'][low_ind].transpose(0,-1,1,2,3)*(1-set_v_to_zero),domain=dataat['xvJ'][low_ind],direction='b'),\n",
    "        emlddmm.Transform(dataat['AJ'][low_ind],direction='b')\n",
    "    ][::-1],XI)\n",
    "\n",
    "\n",
    "    # now we want to interpolate our neuron points here\n",
    "    phiiphiiV = []\n",
    "    for phiiV in phiiVall: # note phiiVall stores left and right for this slab\n",
    "        for vi in phiiV:\n",
    "            # note swap xyz to zyx and back\n",
    "            #phiiphiiV.append( emlddmm.interp(xIat,tform_low_to_at,vi.T[::-1,:,None,None].astype(np.float32))[...,0,0].T.numpy()[...,::-1] )\n",
    "            phiiphiiV.append( emlddmm.interp(xI,tform_low_to_at,vi.T[::-1,:,None,None].astype(np.float32))[...,0,0].T.numpy()[...,::-1] )\n",
    "\n",
    "\n",
    "\n",
    "    if Eall:\n",
    "        # ========== Working here to debug code ==========\n",
    "        Eall_ = np.concatenate(Eall)\n",
    "        # Eall_ = np.array(Eall, dtype=object)\n",
    "        # Eall_ = np.empty(len(Eall),dtype=object)\n",
    "        # Eall_[:] = Eall\n",
    "        # Eall_ = np.concatenate([np.concatenate([e for e in Ealli]) for Ealli in Eall])\n",
    "    else:\n",
    "        Eall_ = np.zeros((0,2),dtype=int)\n",
    "     \n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    for vi,ei in zip(phiiphiiV,Eall_):\n",
    "        lc = Line3DCollection(vi[:,::-1][ei],linewidths=0.5) # flip xyz to zyx\n",
    "        ax.add_collection3d(lc)\n",
    "    ax.set_xlim(xIat[0][0],xIat[0][-1])\n",
    "    ax.set_ylim(xIat[1][0],xIat[1][-1])\n",
    "    ax.set_zlim(xIat[2][0],xIat[2][-1])\n",
    "\n",
    "    \n",
    "    \n",
    "    # then we want to show them with segmentations\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    pc = Poly3DCollection(verts[faces],alpha=0.1)\n",
    "    ax.add_collection3d(pc)\n",
    "\n",
    "    for vi,ei in zip(phiiphiiV,Eall_):\n",
    "        lc = Line3DCollection(vi[:,::-1][ei],linewidths=0.1) # flip xyz to zyx\n",
    "        ax.add_collection3d(lc)\n",
    "\n",
    "\n",
    "    ax.set_xlim(xIat[0][0],xIat[0][-1])\n",
    "    ax.set_ylim(xIat[1][0],xIat[1][-1])\n",
    "    ax.set_zlim(xIat[2][0],xIat[2][-1])\n",
    "\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    zlim = ax.get_zlim()\n",
    "    c = np.array([np.mean(xlim),np.mean(ylim),np.mean(zlim)])\n",
    "    d = np.array([xlim[1]-c[0], ylim[1]-c[1],zlim[1]-c[2]])\n",
    "    maxd = np.max(d)\n",
    "    ax.set_xlim(c[0]-maxd,c[0]+maxd)\n",
    "    ax.set_ylim(c[1]-maxd,c[1]+maxd)\n",
    "    ax.set_zlim(c[2]-maxd,c[2]+maxd)\n",
    "\n",
    "\n",
    "    # sample the structures\n",
    "    VS = []\n",
    "    for vi in phiiphiiV:\n",
    "        tmp = emlddmm.interp([x.astype(np.float64) for x in xS],\n",
    "                       S.astype(np.float64),\n",
    "                       vi.T[::-1,:,None,None].astype(np.float64),\n",
    "                       mode='nearest')[...,0,0].T.numpy()[...,::-1] \n",
    "        VS.append(tmp)\n",
    "    \n",
    "    # NEW in v08\n",
    "    # add some fuzz\n",
    "    # since registration was at 50 micron, I'll add gaussian noise with 50 micron std\n",
    "    VS_noise = []\n",
    "    Sf = S.astype(np.float64)\n",
    "    n_noise = 500\n",
    "    std_noise = 50.0\n",
    "    for n_noise in range(n_noise):\n",
    "        noise = np.random.randn(3)*std_noise\n",
    "        VS_noise_i = []\n",
    "        for vi in phiiphiiV:\n",
    "            vi = np.array(vi)  # COPY! important\n",
    "            vi += noise\n",
    "\n",
    "            tmp = emlddmm.interp([x.astype(np.float64) for x in xS],\n",
    "                           Sf,\n",
    "                           vi.T[::-1,:,None,None].astype(np.float64),\n",
    "                           mode='nearest')[...,0,0].T.numpy()[...,::-1]     \n",
    "            VS_noise_i.append(tmp)\n",
    "        VS_noise.append(VS_noise_i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    neurons.append(phiiphiiV)\n",
    "    \n",
    "    neuron_labels.append(VS)\n",
    "    neuron_labels_noise.append(VS_noise)\n",
    "    neuron_edges.append(Eall_)\n",
    "    neurons_orig.append(V)\n",
    "    \n",
    "    neurons_one_step.append(phiiVall)\n",
    "    # okay now I've got everything mapped\n",
    "    # I need to work on combining outputs\n",
    "    # save the figures I'm interested in\n",
    "    # and combine intoone big figure\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception('Stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images[-1] = Iat[0]/np.quantile(Iat[0],0.99)\n",
    "emlddmm.draw(images,xIat,vmin=0,vmax=1,n_slices=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "affine = np.diag([dIat[0],dIat[1],dIat[2],1.0])\n",
    "affine[:3,-1] = np.array([xIat[0][0],xIat[1][0],xIat[2][0]])\n",
    "vol = nib.Nifti1Image(images[0],affine=affine)\n",
    "nib.save(vol,join(output_dir,'atlas_high.nii'))\n",
    "vol = nib.Nifti1Image(images[1],affine=affine)\n",
    "nib.save(vol,join(output_dir,'atlas_low.nii'))\n",
    "vol = nib.Nifti1Image(images[2],affine=affine)\n",
    "nib.save(vol,join(output_dir,'atlas_nissl.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the atlas transform and apply it to this data\n",
    "# then next we will apply it to all slices\n",
    "# I will just transform the low res data, interpolating twice\n",
    "# then I will transform low res data, combining transforms and interpolating once\n",
    "# then I will loop over all slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "pc = Poly3DCollection(verts[faces],alpha=0.1)\n",
    "ax.add_collection3d(pc)\n",
    "\n",
    "for Vi,Ei in zip(neurons,neuron_edges):\n",
    "    for vi,ei in zip(Vi,Ei):\n",
    "        lc = Line3DCollection(vi[:,::-1][ei],linewidths=0.1,color=np.random.rand(3)) # flip xyz to zyx\n",
    "        ax.add_collection3d(lc)\n",
    "\n",
    "\n",
    "ax.set_xlim(xIat[0][0],xIat[0][-1])\n",
    "ax.set_ylim(xIat[1][0],xIat[1][-1])\n",
    "ax.set_zlim(xIat[2][0],xIat[2][-1])\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "zlim = ax.get_zlim()\n",
    "c = np.array([np.mean(xlim),np.mean(ylim),np.mean(zlim)])\n",
    "d = np.array([xlim[1]-c[0], ylim[1]-c[1],zlim[1]-c[2]])\n",
    "maxd = np.max(d)\n",
    "ax.set_xlim(c[0]-maxd,c[0]+maxd)\n",
    "ax.set_ylim(c[1]-maxd,c[1]+maxd)\n",
    "ax.set_zlim(c[2]-maxd,c[2]+maxd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here it is colored by soma label\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "#ax.view_init(90,90) # yes they look totally flat! somewhere they are getting squished!\n",
    "pc = Poly3DCollection(verts[faces],alpha=0.1)\n",
    "ax.add_collection3d(pc)\n",
    "colors = {}\n",
    "for Vi,Ei,Li in zip(neurons,neuron_edges,neuron_labels):    \n",
    "    for vi,ei,li in zip(Vi,Ei,Li):\n",
    "        labels = np.unique(li)\n",
    "        for lii in li:\n",
    "            if lii.item() not in colors:\n",
    "                colors[lii.item()] = np.random.rand(3)\n",
    "        c = colors[li[0].item()] # use the cell body\n",
    "        lc = Line3DCollection(vi[:,::-1][ei],linewidths=0.1,colors=c) # flip xyz to zyx\n",
    "        ax.add_collection3d(lc)\n",
    "\n",
    "\n",
    "ax.set_xlim(xIat[0][0],xIat[0][-1])\n",
    "ax.set_ylim(xIat[1][0],xIat[1][-1])\n",
    "ax.set_zlim(xIat[2][0],xIat[2][-1])\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "zlim = ax.get_zlim()\n",
    "c = np.array([np.mean(xlim),np.mean(ylim),np.mean(zlim)])\n",
    "d = np.array([xlim[1]-c[0], ylim[1]-c[1],zlim[1]-c[2]])\n",
    "maxd = np.max(d)\n",
    "ax.set_xlim(c[0]-maxd,c[0]+maxd)\n",
    "ax.set_ylim(c[1]-maxd,c[1]+maxd)\n",
    "ax.set_zlim(c[2]-maxd,c[2]+maxd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it again with origin fixing\n",
    "# we need to use the allen atlas coordinate system provided\n",
    "# first we can subtract the location of the first pixel in the volume\n",
    "# then we can permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x0 = np.array([x[0] for x in xS])\n",
    "x1 = np.array([x[-1] for x in xS])\n",
    "\n",
    "verts_ = verts - x0\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "#ax.view_init(90,90) # yes they look totally flat! somewhere they are getting squished!\n",
    "pc = Poly3DCollection(verts_[faces],alpha=0.1)\n",
    "ax.add_collection3d(pc)\n",
    "colors = {}\n",
    "for Vi,Ei,Li in zip(neurons,neuron_edges,neuron_labels):    \n",
    "    for vi,ei,li in zip(Vi,Ei,Li):\n",
    "        vi_ = vi - x0[::-1]\n",
    "        labels = np.unique(li)\n",
    "        for lii in li:\n",
    "            if lii.item() not in colors:\n",
    "                colors[lii.item()] = np.random.rand(3)\n",
    "        c = colors[li[0].item()] # use the cell body\n",
    "        lc = Line3DCollection(vi_[:,::-1][ei],linewidths=0.1,colors=c) # flip xyz to zyx\n",
    "        ax.add_collection3d(lc)\n",
    "\n",
    "\n",
    "#ax.set_xlim(xIat[0][0],xIat[0][-1])\n",
    "#ax.set_ylim(xIat[1][0],xIat[1][-1])\n",
    "#ax.set_zlim(xIat[2][0],xIat[2][-1])\n",
    "\n",
    "ax.set_xlim(np.min(verts_[:,0],0),np.max(verts_[:,0],0))\n",
    "ax.set_ylim(np.min(verts_[:,1],0),np.max(verts_[:,1],0))\n",
    "ax.set_zlim(np.min(verts_[:,2],0),np.max(verts_[:,2],0))\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "zlim = ax.get_zlim()\n",
    "c = np.array([np.mean(xlim),np.mean(ylim),np.mean(zlim)])\n",
    "d = np.array([xlim[1]-c[0], ylim[1]-c[1],zlim[1]-c[2]])\n",
    "maxd = np.max(d)\n",
    "ax.set_xlim(c[0]-maxd,c[0]+maxd)\n",
    "ax.set_ylim(c[1]-maxd,c[1]+maxd)\n",
    "ax.set_zlim(c[2]-maxd,c[2]+maxd)\n",
    "ax.set_xlabel('x0')\n",
    "ax.set_ylabel('x1')\n",
    "ax.set_zlabel('x2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay getting closer\n",
    "# first I'll deal with any flips\n",
    "# then I'll deal with any permutations\n",
    "# in the picture, origin is the superior left anterior corner\n",
    "# and x = posterior, y = inferior, z = right\n",
    "# in my case we have\n",
    "# x=x2=inferior\n",
    "# y = x1 = left\n",
    "# z = x0 = anterior\n",
    "# I have ILA\n",
    "# and they have\n",
    "# PIR\n",
    "# so\n",
    "# first I need to flip L to R (that's y, first axis)\n",
    "# and I need to flip A to P (thats z, 0th axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I deal with flips\n",
    "\n",
    "x0 = np.array([x[0] for x in xS])\n",
    "x1 = np.array([x[-1] for x in xS])\n",
    "\n",
    "verts_ = verts - x0\n",
    "verts_[:,0] = (x1[0]-x0[0]) - verts_[:,0]\n",
    "verts_[:,1] = (x1[1]-x0[1]) - verts_[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "#ax.view_init(90,90) # yes they look totally flat! somewhere they are getting squished!\n",
    "pc = Poly3DCollection(verts_[faces],alpha=0.1)\n",
    "ax.add_collection3d(pc)\n",
    "colors = {}\n",
    "for Vi,Ei,Li in zip(neurons,neuron_edges,neuron_labels):    \n",
    "    for vi,ei,li in zip(Vi,Ei,Li):\n",
    "        # offset (note xyz zyx)\n",
    "        vi_ = vi - x0[::-1]\n",
    "        # flip the first and last (note xyz,zyx)\n",
    "        vi_[:,2] = (x1[0]-x0[0]) - vi_[:,2]\n",
    "        vi_[:,1] = (x1[1]-x0[1]) - vi_[:,1]\n",
    "    \n",
    "        labels = np.unique(li)\n",
    "        for lii in li:\n",
    "            if lii.item() not in colors:\n",
    "                colors[lii.item()] = np.random.rand(3)\n",
    "        c = colors[li[0].item()] # use the cell body\n",
    "        lc = Line3DCollection(vi_[:,::-1][ei],linewidths=0.1,colors=c) # flip xyz to zyx\n",
    "        ax.add_collection3d(lc)\n",
    "\n",
    "\n",
    "#ax.set_xlim(xIat[0][0],xIat[0][-1])\n",
    "#ax.set_ylim(xIat[1][0],xIat[1][-1])\n",
    "#ax.set_zlim(xIat[2][0],xIat[2][-1])\n",
    "\n",
    "ax.set_xlim(np.min(verts_[:,0],0),np.max(verts_[:,0],0))\n",
    "ax.set_ylim(np.min(verts_[:,1],0),np.max(verts_[:,1],0))\n",
    "ax.set_zlim(np.min(verts_[:,2],0),np.max(verts_[:,2],0))\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "zlim = ax.get_zlim()\n",
    "c = np.array([np.mean(xlim),np.mean(ylim),np.mean(zlim)])\n",
    "d = np.array([xlim[1]-c[0], ylim[1]-c[1],zlim[1]-c[2]])\n",
    "maxd = np.max(d)\n",
    "ax.set_xlim(c[0]-maxd,c[0]+maxd)\n",
    "ax.set_ylim(c[1]-maxd,c[1]+maxd)\n",
    "ax.set_zlim(c[2]-maxd,c[2]+maxd)\n",
    "ax.set_xlabel('x0=z')\n",
    "ax.set_ylabel('x1=y')\n",
    "ax.set_zlabel('x2=x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay last step\n",
    "# I had ILA\n",
    "# and they have\n",
    "# PIR\n",
    "# then I flipped the 0th and 1th (i.e. y and z)\n",
    "# to get IRP\n",
    "# now I need to permute the axes to make z first\n",
    "# we need to change the order to go zxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I deal with flips\n",
    "\n",
    "x0 = np.array([x[0] for x in xS])\n",
    "x1 = np.array([x[-1] for x in xS])\n",
    "\n",
    "verts_ = verts - x0\n",
    "verts_[:,0] = (x1[0]-x0[0]) - verts_[:,0]\n",
    "verts_[:,1] = (x1[1]-x0[1]) - verts_[:,1]\n",
    "\n",
    "# now permute\n",
    "permutation = [2,0,1] # no\n",
    "permutation = [1,2,0] # yes! note this permutation is cyclic, so doesn't change handedness\n",
    "verts_ = verts_[:,permutation]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "#ax.view_init(90,90) # yes they look totally flat! somewhere they are getting squished!\n",
    "ax.view_init(elev=30,azim=45,vertical_axis='x')\n",
    "pc = Poly3DCollection(verts_[faces],alpha=0.1)\n",
    "ax.add_collection3d(pc)\n",
    "colors = {}\n",
    "for Vi,Ei,Li in zip(neurons,neuron_edges,neuron_labels):    \n",
    "    for vi,ei,li in zip(Vi,Ei,Li):\n",
    "        # offset (note xyz zyx)\n",
    "        vi_ = vi - x0[::-1]\n",
    "        # flip the first and last (note xyz,zyx)\n",
    "        vi_[:,2] = (x1[0]-x0[0]) - vi_[:,2]\n",
    "        vi_[:,1] = (x1[1]-x0[1]) - vi_[:,1]\n",
    "        \n",
    "        # use the same permutation as above\n",
    "        vi_ = vi_[:,::-1][:,permutation][:,::-1]\n",
    "    \n",
    "        labels = np.unique(li)\n",
    "        for lii in li:\n",
    "            if lii.item() not in colors:\n",
    "                colors[lii.item()] = np.random.rand(3)\n",
    "        c = colors[li[0].item()] # use the cell body\n",
    "        lc = Line3DCollection(vi_[:,::-1][ei],linewidths=0.1,colors=c) # flip xyz to zyx\n",
    "        ax.add_collection3d(lc)\n",
    "\n",
    "\n",
    "#ax.set_xlim(xIat[0][0],xIat[0][-1])\n",
    "#ax.set_ylim(xIat[1][0],xIat[1][-1])\n",
    "#ax.set_zlim(xIat[2][0],xIat[2][-1])\n",
    "\n",
    "ax.set_xlim(np.min(verts_[:,0],0),np.max(verts_[:,0],0))\n",
    "ax.set_ylim(np.min(verts_[:,1],0),np.max(verts_[:,1],0))\n",
    "ax.set_zlim(np.min(verts_[:,2],0),np.max(verts_[:,2],0))\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "zlim = ax.get_zlim()\n",
    "c = np.array([np.mean(xlim),np.mean(ylim),np.mean(zlim)])\n",
    "d = np.array([xlim[1]-c[0], ylim[1]-c[1],zlim[1]-c[2]])\n",
    "maxd = np.max(d)\n",
    "ax.set_xlim(c[0]-maxd,c[0]+maxd)\n",
    "ax.set_ylim(c[1]-maxd,c[1]+maxd)\n",
    "ax.set_zlim(c[2]-maxd,c[2]+maxd)\n",
    "ax.set_xlabel('x0=z')\n",
    "ax.set_ylabel('x1=y')\n",
    "ax.set_zlabel('x2=x')\n",
    "\n",
    "ax.invert_xaxis() # this is important to make z look like it is pointing right\n",
    "\n",
    "import os\n",
    "\n",
    "fig.savefig(os.path.join(output_dir,'neuron_ccf_space.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "outdir = f'dragonfly_outputs/{brain}/dragonfly_joint_outputs'\n",
    "os.makedirs(outdir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to write out all the swc files\n",
    "# TODO, look through carefully\n",
    "count1 = 0\n",
    "count = 0\n",
    "with open(join(outdir,'soma_label_v08.csv'),'wt') as f_soma:\n",
    "    f_soma.write('name, id\\n')\n",
    "    for Vi,Ei,Li,Filesi in zip(neurons,neuron_edges,neuron_labels,files_all):\n",
    "        count2 = 0\n",
    "        for vi,ei,li,filei in zip(Vi,Ei,Li,Filesi):        \n",
    "            filename_end = split(filei)[-1]\n",
    "            \n",
    "            # I need to write out swc from vertices and edges\n",
    "            # outname = os.path.join(outdir,f'image_{count1:06d}_neuron_{count2:06d}.swc')            \n",
    "            outname = os.path.join(outdir,filename_end.replace('.swc','_mapped.swc'))\n",
    "            \n",
    "            f_soma.write(filename_end+','+str(int(li[0].item()))+'\\n')\n",
    "            with open(outname,'wt') as f:\n",
    "                #f.write(f'# Generated by Daniel Tward\\n')\n",
    "                for i in range(len(vi)):\n",
    "                    # TODO\n",
    "                    # we need to update the radius\n",
    "                    radius = 1.0\n",
    "\n",
    "                    parent = ei[np.where(ei[:,1] == i)[0],0]\n",
    "\n",
    "                    if parent.size == 0:\n",
    "                        parent = -1\n",
    "                    else: \n",
    "                        parent = parent[0] + 1\n",
    "                    # we print the vertex number, starting at 1\n",
    "                    # then we print the structure label\n",
    "                    # then we print the components in xyz order (we reverse the zyx)\n",
    "                    # then we print the radius, which is just set to 1 \n",
    "                    # then we print the parent\n",
    "                    f.write(f'{i+1},{int(li[i].item())},{vi[i,2]},{vi[i,1]},{vi[i,0]},{radius},{parent}\\n')\n",
    "\n",
    "            count += 1\n",
    "            count2 += 1\n",
    "        count1 += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is a copy of the above, but with the transform\n",
    "count1 = 0\n",
    "count = 0\n",
    "with open(join(outdir,'soma_label_v08.csv'),'wt') as f_soma:\n",
    "    f_soma.write('name, id\\n')\n",
    "    for Vi,Ei,Li,Filesi in zip(neurons,neuron_edges,neuron_labels,files_all):\n",
    "        count2 = 0\n",
    "        for vi,ei,li,filei in zip(Vi,Ei,Li,Filesi):     \n",
    "            vi_ = vi - x0[::-1]\n",
    "            # flip the first and last (note xyz,zyx)\n",
    "            vi_[:,2] = (x1[0]-x0[0]) - vi_[:,2]\n",
    "            vi_[:,1] = (x1[1]-x0[1]) - vi_[:,1]\n",
    "\n",
    "            # use the same permutation as above\n",
    "            vi_ = vi_[:,::-1][:,permutation][:,::-1]\n",
    "\n",
    "\n",
    "            filename_end = split(filei)[-1]\n",
    "            \n",
    "            # I need to write out swc from vertices and edges\n",
    "            outname = os.path.join(outdir,f'image_{count1:06d}_neuron_{count2:06d}.swc')\n",
    "            outname = os.path.join(outdir,filename_end.replace('.swc','_mapped_ccf_permuted.swc'))\n",
    "            \n",
    "            f_soma.write(filename_end+','+str(int(li[0].item()))+'\\n')\n",
    "            with open(outname,'wt') as f:\n",
    "                #f.write(f'# Generated by Daniel Tward\\n')\n",
    "                for i in range(len(vi_)):\n",
    "                    # TODO\n",
    "                    # we need to update the radius\n",
    "                    radius = 1.0\n",
    "\n",
    "                    parent = ei[np.where(ei[:,1] == i)[0],0]\n",
    "\n",
    "                    if parent.size == 0:\n",
    "                        parent = -1\n",
    "                    else: \n",
    "                        parent = parent[0] + 1\n",
    "                    # we print the vertex number, starting at 1\n",
    "                    # then we print the structure label\n",
    "                    # then we print the components in xyz order (we reverse the zyx)\n",
    "                    # then we print the radius, which is just set to 1 \n",
    "                    # then we print the parent\n",
    "                    f.write(f'{i+1},{int(li[i].item())},{vi_[i,2]},{vi_[i,1]},{vi_[i,0]},{radius},{parent}\\n')\n",
    "\n",
    "            count += 1\n",
    "            count2 += 1\n",
    "        count1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(outdir,'soma_label_prob_v08.csv'),'wt') as f_soma:\n",
    "    # write out the label headers\n",
    "    f_soma.write('name, ', )\n",
    "    for l in labels:\n",
    "        f_soma.write(f'{l}, ')\n",
    "    f_soma.write('\\n')\n",
    "    \n",
    "    for Li,Filesi in zip(neuron_labels_noise,files_all):        \n",
    "        # note Li is length 50 and consists of 50 samples\n",
    "        # I transpose the first to dims below\n",
    "        for li,filei in zip(zip(*Li),Filesi):        \n",
    "            filename_end = split(filei)[-1]\n",
    "            \n",
    "            # get the soma (first entry)\n",
    "            neuron_labels = [li[i][0] for i in range(len(li))]\n",
    "            neuron_prob = np.zeros(len(labels))\n",
    "            for l in neuron_labels:\n",
    "                neuron_prob += labels==l\n",
    "            neuron_prob /= np.sum(neuron_prob)\n",
    "            \n",
    "            \n",
    "            f_soma.write(filename_end+', '+ ', '.join([str(p) for p in neuron_prob]) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need up to here, this will save all the outputs we need\n",
    "# neurons mapped to the atlas\n",
    "# neurons mapped to the atlas, but permuted and shifted to match the cooridnate system conventions\n",
    "# labels for each neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# brain = 'TME08-1'\n",
    "# label_csv_path = f'home/abenneck/dragonfly_work/dragonfly_outputs/{brain}/dragonfly_joint_outputs/soma_label_v08.csv'\n",
    "# data = pd.read_csv(label_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('End here')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
